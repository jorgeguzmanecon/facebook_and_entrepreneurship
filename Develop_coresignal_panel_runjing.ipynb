{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Clear all variables to free up memory\n",
    "for name in dir():\n",
    "    if not name.startswith('_') and name not in ['gc']:\n",
    "        del globals()[name]\n",
    "\n",
    "gc.collect()\n",
    "print(\"All variables cleared and garbage collected\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "\n",
    "os.chdir('/shared/share_scp/coresignal/gitrepo_facebook')\n",
    "\n",
    "if '/shared/share_scp/coresignal/gitrepo_facebook' in sys.modules:\n",
    "    for module_name in list(sys.modules.keys()):\n",
    "        if module_name.startswith('university_name_matcher'):\n",
    "            del sys.modules[module_name]\n",
    "\n",
    "from university_name_matcher import university_name_matcher\n",
    "umatcher = university_name_matcher()\n",
    "\n",
    "os.chdir('/shared/share_scp/coresignal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87480a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "del globals()['all_experience']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be80c3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Changelog \n",
    "### Changes before 10/6\n",
    "1. Data now spans all people how finished college form 1995 to 2012 \n",
    "\n",
    "### Changes after meeting 10/6\n",
    "\n",
    "1. The 'founder_inc' variables are re-created with much higher values. The issue was that they were being matched as case-sensitive (i.e., 'inc' matched, but not 'Inc' or 'INC') and they had not included 'company' or 'co'\n",
    "2. The 'owner' variable had been cleaned to remove all definitions such as 'program owner' that were more jobs, but the coowner variable still included them, these have been removed.\n",
    "\n",
    "### Changes after meeting on 11/12\n",
    "\n",
    "1. Added code to get all the cofounders based on URL match of startup only and founder title, and create a separate file for that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3c9e3",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Convert the raw files into an analysis file\n",
    "These are the files created from Python CSVs into Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d275b",
   "metadata": {},
   "source": [
    "### 1.1 Read the files on education experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_adopted_facebook = umatcher.load_university_data() \n",
    "x = universities_adopted_facebook[universities_adopted_facebook['instnm'].duplicated()].instnm\n",
    "\n",
    "print(\"Number of duplicate university IDs:\", universities_adopted_facebook[universities_adopted_facebook['instnm'].isin(x)].shape[0])\n",
    "\n",
    "\n",
    "print(\"Number of NA in name\", universities_adopted_facebook['instnm'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "education_files = sorted(glob.glob('processed_data2/coresignal_member_education_*linkedin*.pkl'))\n",
    "print(f'Found {len(education_files)} education files')\n",
    "coresignal_member_education_all = pd.concat(\n",
    "    [pd.read_pickle(f) for f in education_files],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "coresignal_member_education_all['member_id'] = coresignal_member_education_all['member_id'].astype(int)\n",
    "coresignal_member_education_all = coresignal_member_education_all.drop_duplicates()\n",
    "member_ids = coresignal_member_education_all['member_id'].astype(int).unique()\n",
    "print(f\"Number of unique member IDs: {len(member_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scratch\n",
    "print(\"Checking for duplicates in the combined DataFrame\")\n",
    "dups0= coresignal_member_education_all.duplicated(['id']).sum()\n",
    "total0 = coresignal_member_education_all.shape[0]\n",
    "coresignal_member_education_all = coresignal_member_education_all[~coresignal_member_education_all.title.str.contains(\"university of phoenix|devry university\", case=False, na=False)]\n",
    "dups1 = coresignal_member_education_all.duplicated(['id']).sum()\n",
    "total1 = coresignal_member_education_all.shape[0]\n",
    "\n",
    "pct0 = dups0 / total0 * 100\n",
    "pct1 = dups1 / total1 * 100\n",
    "print(f\"Total duplicates found: {dups0:,} ({pct0:.2f}%). Dropped to {dups1:,} ({pct1:.2f}%) after filtering for 'university of phoenix|devry university'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960433ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "# Function to safely calculate Levenshtein distance\n",
    "def safe_levenshtein(str1, str2):\n",
    "    if pd.isna(str1) or pd.isna(str2):\n",
    "        return np.nan\n",
    "    return levenshtein_distance(str(str1).lower(), str(str2).lower())\n",
    "\n",
    "# Calculate Levenshtein distance using .loc to avoid SettingWithCopyWarning\n",
    "coresignal_member_education_all.loc[:, 'levenshtein_distance'] = coresignal_member_education_all.apply(\n",
    "    lambda row: safe_levenshtein(row['title'], row['instnm']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Levenshtein distances between title and university name:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coresignal_member_education_all.loc[:, 'is_duplicated'] = coresignal_member_education_all.duplicated(['id'])\n",
    "\n",
    "pd.concat([coresignal_member_education_all[coresignal_member_education_all['is_duplicated']].sample(10),\n",
    "              coresignal_member_education_all[~coresignal_member_education_all['is_duplicated']].sample(10)],\n",
    "              ignore_index=True)[['id', 'member_id', 'title', 'instnm', 'levenshtein_distance', 'is_duplicated']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots for comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot histogram for non-duplicated records\n",
    "non_duplicated_distances = coresignal_member_education_all[~coresignal_member_education_all['is_duplicated']]['levenshtein_distance'].dropna()\n",
    "ax1.hist(non_duplicated_distances, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax1.set_title('Levenshtein Distance Distribution\\n(Non-Duplicated Records)')\n",
    "ax1.set_xlabel('Levenshtein Distance')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot histogram for duplicated records\n",
    "duplicated_distances = coresignal_member_education_all[coresignal_member_education_all['is_duplicated']]['levenshtein_distance'].dropna()\n",
    "ax2.hist(duplicated_distances, bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.set_title('Levenshtein Distance Distribution\\n(Duplicated Records)')\n",
    "ax2.set_xlabel('Levenshtein Distance')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Non-duplicated records - Mean distance: {non_duplicated_distances.mean():.2f}, Median: {non_duplicated_distances.median():.2f}\")\n",
    "print(f\"Duplicated records - Mean distance: {duplicated_distances.mean():.2f}, Median: {duplicated_distances.median():.2f}\")\n",
    "print(f\"Non-duplicated count: {len(non_duplicated_distances):,}\")\n",
    "print(f\"Duplicated count: {len(duplicated_distances):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coresignal_member_education_all = coresignal_member_education_all[~coresignal_member_education_all['is_duplicated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54812691",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = coresignal_member_education_all.shape[0]\n",
    "coresignal_member_education_all = coresignal_member_education_all[~coresignal_member_education_all['school_url'].str.endswith('linkedin.com/edu/school')]\n",
    "print(f\"Total rows before filtering: {total_rows:,}\")\n",
    "print(f\"Total rows after filtering:  {coresignal_member_education_all.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef498545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for bachelor's degrees or undergrad\n",
    "coresignal_member_education = coresignal_member_education_all[\n",
    "    coresignal_member_education_all['subtitle'].str.lower().str.contains(r'bachelor\\'?s?|undergrad|\\sb\\.a\\.|b\\.s\\.', na=False)\n",
    "]\n",
    "print(f\"Filtered from {len(coresignal_member_education_all):,} to {len(coresignal_member_education):,} records for bachelor's or undergrad degrees.\")\n",
    "\n",
    "\n",
    "print(f\"Deleting coresignal_member_education_all object\")\n",
    "\n",
    "del coresignal_member_education_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521592e",
   "metadata": {},
   "source": [
    "### 1.2 Read the files on employment experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def read_pickle_file(filepath):\n",
    "    return pd.read_pickle(filepath)\n",
    "\n",
    "# Find all processed pickle files matching the pattern\n",
    "os.chdir('/shared/share_scp/coresignal') #make sure it is in the right directory\n",
    "\n",
    "processed_files = sorted(glob.glob('processed_data/coresignal_member_experience_*START*.pkl'))\n",
    "print(f'Found {len(processed_files):,} files with experience.')\n",
    "\n",
    "# Use parallel processing with manual progress tracking\n",
    "max_workers = min(len(processed_files), multiprocessing.cpu_count())\n",
    "print(f'Using {max_workers} workers for parallel processing.')\n",
    "\n",
    "dataframes = []\n",
    "start_time = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_file = {executor.submit(read_pickle_file, file): file \n",
    "                     for file in processed_files}\n",
    "    \n",
    "    # Process completed tasks and show progress\n",
    "    for i, future in enumerate(as_completed(future_to_file), 1):\n",
    "        dataframes.append(future.result())\n",
    "        \n",
    "        # Print progress every 10 files or at the end\n",
    "        if i % 10 == 0 or i == len(processed_files):\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = i / elapsed if elapsed > 0 else 0\n",
    "            remaining = len(processed_files) - i\n",
    "            eta = remaining / rate if rate > 0 else 0\n",
    "            \n",
    "            print(f\"Progress: {i:,}/{len(processed_files):,} files ({i/len(processed_files)*100:.1f}%) | \"\n",
    "                  f\"Rate: {rate:.1f} files/sec | \"\n",
    "                  f\"Time Left: {eta:.0f}s | \"\n",
    "                  f\"Elapsed: {elapsed:.0f}s\")\n",
    "\n",
    "print(\"Concatenating dataframes...\")\n",
    "all_experience = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(f\"Total rows in all experience data: {len(all_experience):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e90fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to those with education records that will be our focus\n",
    "all_experience = all_experience[all_experience['member_id'].isin(coresignal_member_education['member_id'])]\n",
    "print(f\"Total rows in all experience data after filtering to undergrad graduates: {len(all_experience):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e07ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Total rows in all experience data: {len(all_experience):,}\")\n",
    "print(\"Removing duplicates...\")\n",
    "key_columns = ['member_id','location','company_url','duration','order_in_profile','company_id', 'company_name', 'title', 'date_from', 'date_to']\n",
    "all_experience = all_experience.drop_duplicates(subset=['id'])\n",
    "print(f\"Total rows in all experience data (after removing duplicates): {len(all_experience):,}\")\n",
    "elapsed_time = time.time() - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "print(f\"Time taken to remove duplicates: {minutes}m {seconds}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba573b9",
   "metadata": {},
   "source": [
    "### 1.3 Testing and validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of entries by graduation year\n",
    "\n",
    "\n",
    "# Create subplots for graduation year and start year\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot graduation year\n",
    "grad_year_counts = coresignal_member_education.loc[(coresignal_member_education['year_to'] >= 1994) & (coresignal_member_education['year_to'] <= 2011),'year_to'].value_counts().sort_index()\n",
    "ax1.bar(grad_year_counts.index, grad_year_counts.values, alpha=0.7, color='steelblue')\n",
    "ax1.set_title('Number of Education Entries by Graduation Year (1994-2011)')\n",
    "ax1.set_xlabel('Graduation Year')\n",
    "ax1.set_ylabel('Number of Entries')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot start year\n",
    "start_year_counts = coresignal_member_education.loc[(coresignal_member_education['year_from'] >= 1994) & (coresignal_member_education['year_from'] <= 2011),'year_from'].value_counts().sort_index()\n",
    "ax2.bar(start_year_counts.index, start_year_counts.values, alpha=0.7, color='orange')\n",
    "ax2.set_title('Number of Education Entries by Start Year (1994-2011)')\n",
    "ax2.set_xlabel('Start Year')\n",
    "ax2.set_ylabel('Number of Entries')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.tick_params(axis='x', rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 50 universities by number of graduates\n",
    "top_50_universities = coresignal_member_education['instnm'].value_counts().head(50)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "bars = plt.barh(range(len(top_50_universities)), top_50_universities.values, color='steelblue', alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.yticks(range(len(top_50_universities)), top_50_universities.index, fontsize=8)\n",
    "plt.xlabel('Number of Graduates')\n",
    "plt.title('Top 50 Universities by Number of Graduates in Dataset')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, top_50_universities.values)):\n",
    "    plt.text(value + max(top_50_universities.values) * 0.01, i, f'{value:,}', \n",
    "             va='center', fontsize=7)\n",
    "\n",
    "# Invert y-axis so highest counts are at top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Filter data for University of Texas at Austin\n",
    "ut_austin_data = coresignal_member_education[\n",
    "    coresignal_member_education['instnm'] == 'The University of Texas at Austin'\n",
    "]\n",
    "\n",
    "# Get graduation year counts for UT Austin\n",
    "ut_austin_grad_years = ut_austin_data['year_to'].value_counts().sort_index()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(ut_austin_grad_years.index, ut_austin_grad_years.values, color='orange', alpha=0.7)\n",
    "plt.title('Number of Graduates by Year - University of Texas at Austin')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Number of Graduates')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for year, count in ut_austin_grad_years.items():\n",
    "    plt.text(year, count + max(ut_austin_grad_years.values) * 0.01, \n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total UT Austin graduates in dataset: {len(ut_austin_data):,}\")\n",
    "print(f\"Year range: {ut_austin_grad_years.index.min()} - {ut_austin_grad_years.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67159ce0",
   "metadata": {},
   "source": [
    "### 1.4 Output and save the analysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "coresignal_member_education.to_pickle('coresignal_member_education_AnalysisFile_09302025.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_experience.to_pickle('all_experience_AnalysisFile_09302025.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe449f",
   "metadata": {},
   "source": [
    "# 2. Create the Stata analysis files from the complete datasets\n",
    "Data loading from base files is done and now we add the things we are going to study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7d062",
   "metadata": {},
   "source": [
    "## 2.1 Setup and variable creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a61b1",
   "metadata": {},
   "source": [
    "### 2.1.1 Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data from pickle files instead of re-creating it. \n",
    "# Uncomment as necessary\n",
    "\n",
    "coresignal_member_education = pd.read_pickle('coresignal_member_education_AnalysisFile_09302025.pkl')\n",
    "all_experience = pd.read_pickle('all_experience_AnalysisFile_09302025.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21246c8a",
   "metadata": {},
   "source": [
    "### 2.1.2 Create owner variables directly from titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot0 = all_experience.shape[0]\n",
    "all_experience = all_experience[~all_experience.date_from.isnull()]\n",
    "tot1 = all_experience.shape[0]\n",
    "print(f\"Dropped {tot0 - tot1:,} rows with null date_from ({((tot0 - tot1)/tot0*100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3331acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_experience = all_experience.sample(frac=.3)\n",
    "# This cell takes about 5 minutes to run\n",
    "print(\"variable: job_from\",flush=True)\n",
    "all_experience['job_from'] = all_experience['date_from'].str.extract(r'(\\d{4})').astype(float)\n",
    "\n",
    "print(\"variable: is_founder_only\",flush=True)\n",
    "all_experience['is_founder_only'] = all_experience['title'].str.contains('founder', case=False, na=False) \n",
    "\n",
    "print(\"variable: is_owner_only\",flush=True)\n",
    "all_experience['is_owner_only'] = all_experience['title'].str.contains(r'owner\\b', case=False, na=False)\n",
    "\n",
    "print(\"variable: is_founder_or_owner\",flush=True)\n",
    "all_experience['is_founder_or_owner'] = all_experience['is_founder_only'] | all_experience['is_owner_only']\n",
    "\n",
    "print(\"variable: is_founder_or_owner_with_url, is_founder_or_owner_inc\",flush=True)\n",
    "all_experience['is_founder_or_owner_with_url'] = all_experience['is_founder_or_owner'] & all_experience['company_url'].notna()\n",
    "all_experience['is_founder_or_owner_inc'] = all_experience['is_founder_or_owner'] & all_experience['company_name'].str.contains(r'\\b(inc|corp|corporation|co|incorporated)\\b', na=False, case=False)\n",
    "\n",
    "print(\"variables: cofounder/coowner titles\",flush=True)\n",
    "all_experience['is_cofounder_or_coowner_title'] = all_experience['title'].str.contains(r'co[-\\s]?founder|co[-\\s]?owner', case=False, na=False)\n",
    "all_experience['is_cofounder_only_title'] = all_experience['title'].str.contains(r'co[-\\s]?founder', case=False, na=False)\n",
    "all_experience['is_coowner_only_title'] = all_experience['title'].str.contains(r'co[-\\s]?owner', case=False, na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "owner_columns = [col for col in all_experience.columns if 'owner' in col.lower()]\n",
    "#all_experience = dd.from_pandas(all_experience, npartitions=6)\n",
    "\n",
    "all_experience['job_from'] = all_experience['date_from'].str.extract(r'(\\d{4})').astype('Int64')\n",
    "all_experience['long_title'] = all_experience['title'].str.split().str.len() >= 4\n",
    "\n",
    "print(f\"creating mask_non_owners\", flush=True)\n",
    "mask_non_owners =(all_experience['long_title'] | \n",
    "        all_experience['title'].str.contains(r'(product|assistant to|business process|program|process) owner', case=False, na=False) |        \n",
    "        (all_experience['title'] == \"Owner Advisor\")\n",
    ")         \n",
    "owners = all_experience[owner_columns].fillna(False)\n",
    "owners = owners.mask(cond=mask_non_owners, other=False)\n",
    "all_experience[owner_columns] = owners\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789baca2",
   "metadata": {},
   "source": [
    "### 2.1.3 Create flag for franchising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure company_name is categorical for efficiency\n",
    "all_experience['company_name'] = all_experience['company_name'].astype('category')\n",
    "\n",
    "# --- Founders and owners separately ---\n",
    "founders = (\n",
    "    all_experience[all_experience['is_founder_only']]\n",
    "    .groupby('company_name', observed=True)['member_id']\n",
    "    .nunique()\n",
    "    .rename('num_unique_founders')\n",
    ")\n",
    "\n",
    "owners = (\n",
    "    all_experience[all_experience['is_owner_only']]\n",
    "    .groupby('company_name', observed=True)['member_id']\n",
    "    .nunique()\n",
    "    .rename('num_unique_owners')\n",
    ")\n",
    "\n",
    "# --- Combined (either founder or owner) ---\n",
    "founder_or_owner = (\n",
    "    all_experience[all_experience['is_founder_only'] | all_experience['is_owner_only']]\n",
    "    .groupby('company_name', observed=True)['member_id']\n",
    "    .nunique()\n",
    "    .rename('num_unique_founders_or_owners')\n",
    ")\n",
    "\n",
    "# --- Merge all together ---\n",
    "companies_ownership_by_name = (\n",
    "    pd.concat([founders, owners, founder_or_owner], axis=1)\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    "    .sort_values('num_unique_founders_or_owners', ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_ownership_by_name = companies_ownership_by_name[companies_ownership_by_name['company_name'].notna() & (companies_ownership_by_name['company_name'] != '-')]\n",
    "companies_ownership_by_name = companies_ownership_by_name[~companies_ownership_by_name['company_name'].str.match(r'self[-\\s]?employed|^freelance$|^consultant$|^independent consultant$|^business owner$|^private practice$|^Stealth startup$|^stealth|^startup|^entrepreneur$', case=False, na=False)]\n",
    "companies_ownership_by_name = companies_ownership_by_name[~companies_ownership_by_name['company_name'].str.match(r'^\\'?self', case=False, na=False)]\n",
    "companies_ownership_by_name = companies_ownership_by_name[~(companies_ownership_by_name['company_name'] == \".\")]\n",
    "companies_ownership_by_name = companies_ownership_by_name[~(companies_ownership_by_name['company_name'].isin(['owner','confidential','none']))]\n",
    "companies_ownership_by_name['share_founders_vs_owners'] = companies_ownership_by_name['num_unique_founders'] / companies_ownership_by_name['num_unique_founders_or_owners'].replace(0, pd.NA)\n",
    "\n",
    "\n",
    "\n",
    "#There are some odd companies giving 'founder' titles around\n",
    "mask = (companies_ownership_by_name['share_founders_vs_owners'] > 0.7)\n",
    "companies_ownership_by_name  = companies_ownership_by_name[~mask]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0939fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(companies_ownership_by_name.tail(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "franchises = companies_ownership_by_name['num_unique_founders_or_owners'] > 15 & (companies_ownership_by_name['share_founders_vs_owners'] < 0.1)\n",
    "\n",
    "all_experience['franchise_founder_or_owner'] = all_experience['company_name'].isin(companies_ownership_by_name[franchises]['company_name']) & all_experience['is_founder_or_owner']\n",
    "all_experience['franchise_owner'] = all_experience['company_name'].isin(companies_ownership_by_name[franchises]['company_name']) & all_experience['is_owner_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073b78c",
   "metadata": {},
   "source": [
    "### 2.1.4 Develop different definitions of co-owner / co-founder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experience['company_url'] = all_experience['company_url'].astype('category')\n",
    "found_own = all_experience[all_experience['is_founder_or_owner']] \n",
    "companies_ownership_by_url = found_own.groupby('company_url', as_index=False, observed = True).agg({\n",
    "    'is_founder_only': 'sum',\n",
    "    'is_owner_only': 'sum'\n",
    "}).sort_values(['is_founder_only', 'is_owner_only'], ascending=False)\n",
    "\n",
    "companies_ownership_by_url = companies_ownership_by_url[companies_ownership_by_url['company_url'].notna()]\n",
    "\n",
    "\n",
    "companies_ownership_by_url['total_founders_owners'] = companies_ownership_by_url['is_founder_only'] + companies_ownership_by_url['is_owner_only']\n",
    "\n",
    "companies_ownership_by_url = companies_ownership_by_url.sort_values('total_founders_owners', ascending=False)\n",
    "cofounder_companies = companies_ownership_by_url[companies_ownership_by_url['total_founders_owners'].between(2, 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experience['cofound_coown_same_url'] = all_experience['is_founder_or_owner'] & all_experience['company_url'].isin(cofounder_companies['company_url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experience.to_pickle('all_experience_latest.pkl')\n",
    "coresignal_member_education.to_pickle('coresignal_member_education_latest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94d10e",
   "metadata": {},
   "source": [
    "## 2.2 Merge education and experience and create necessary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53595b3c",
   "metadata": {},
   "source": [
    "### 2.2.1 Merge data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5ead5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging experience and education data...\n",
      "Loading education data from pickle...\n",
      "Loading experience data from pickle...\n",
      "Loading experience data from pickle...\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "os.chdir('/shared/share_scp/coresignal')\n",
    "print(\"Merging experience and education data...\")\n",
    "\n",
    "if 'coresignal_member_education' not in globals():\n",
    "    print(\"Loading education data from pickle...\")\n",
    "    coresignal_member_education = pd.read_pickle('coresignal_member_education_latest.pkl')\n",
    "else:\n",
    "    print(\"Using existing education data in memory...\")\n",
    "\n",
    "print(f\"Number of unique member IDs in education data: {coresignal_member_education['member_id'].nunique():,}\",flush=True)\n",
    "\n",
    "if 'all_experience' not in globals():\n",
    "    print(\"Loading experience data from pickle...\")\n",
    "    all_experience = pd.read_pickle('all_experience_latest.pkl')\n",
    "else:   \n",
    "    print(\"Using existing experience data in memory...\")\n",
    "\n",
    "print(f\"Number of unique member IDs in experience data: {all_experience['member_id'].nunique():,}\",flush=True)\n",
    "\n",
    "print(\"Performing merge on member_id...\",flush=True)\n",
    "graduates_with_education_job_level = pd.merge(all_experience, coresignal_member_education, on='member_id',suffixes=('_experience', '_education'))\n",
    "print(f\"Total rows after merge: {len(graduates_with_education_job_level):,}\",flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a50a6a",
   "metadata": {},
   "source": [
    "### 2.2.2 Create additional variables in merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aebfb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating worked_as_engineer and worked_in_sales flags...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Calculating worked_as_engineer and worked_in_sales flags...\")\n",
    "graduates_with_education_job_level['worked_as_engineer'] = graduates_with_education_job_level['title_experience'].str.contains('engineer', case=False, na=False)\n",
    "graduates_with_education_job_level['worked_in_sales'] = graduates_with_education_job_level['title_experience'].str.contains('sales', case=False, na=False)\n",
    "\n",
    "# 20_589_319 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeccd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graduates_with_education_job_level.to_pickle('graduates_with_education_job_level_latest.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a615b10",
   "metadata": {},
   "source": [
    "## 2.3 Collapse at the level of the graduate instead of the experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b58783",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_own_columns = [col for col in all_experience.columns if 'found' in col.lower() or 'own' in col.lower()]\n",
    "\n",
    "cols =   ['worked_as_engineer', 'worked_in_sales'] + found_own_columns \n",
    "print(\"cols: \", \", \".join(cols))\n",
    "    \n",
    "for col in cols:\n",
    "    for i in [3,5,10]:\n",
    "        graduates_with_education_job_level[f'{col}_{i}_years'] = graduates_with_education_job_level[col] & (graduates_with_education_job_level['job_from'] <= (graduates_with_education_job_level['year_to'] + i))\n",
    "\n",
    "max_cols = {}\n",
    "for col in cols:\n",
    "    for i in [3, 5, 10]:\n",
    "        col_name = f'{col}_{i}_years'\n",
    "        max_cols[col_name] = 'max'\n",
    "\n",
    "\n",
    "# Aggregate the data\n",
    "graduates_person_level = graduates_with_education_job_level.groupby(['member_id', 'year_to', 'year_from', 'title_education', 'subtitle', 'unitid'], dropna=False).agg({    \n",
    "    **max_cols\n",
    "    }).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aafa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "graduates_person_level.rename(columns={\n",
    "    'year_from': 'year_start_college',\n",
    "    'year_to': 'year_end_college',\n",
    "    'member_id': 'linkedin_member_id',\n",
    "    'title_education': 'university_title',\n",
    "    'subtitle': 'university_major_raw'\n",
    "}, inplace=True)\n",
    "\n",
    "graduates_person_level.columns\n",
    "\n",
    "\n",
    "graduates_person_level.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858f3c2",
   "metadata": {},
   "source": [
    "## 2.4 Add major to the graduate file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfaaeff",
   "metadata": {},
   "source": [
    "Create the graduate file, one line per graduate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d4c47",
   "metadata": {},
   "source": [
    "Keep only those graduates that obtained a bachelors based on the subtitle of the education row (this is a second cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where university_major_raw contains only generic degree terms without specific major\n",
    "generic_patterns = [\n",
    "    r'^bachelor\\'?s?\\s*degree$',\n",
    "    r'^b\\.?s\\.?$',\n",
    "    r'^b\\.?a\\.?$', \n",
    "    r'^bachelor\\'?s?$',\n",
    "    r'^degree$',\n",
    "    r'^undergraduate$',\n",
    "    r'^bachelor of science(\\s*\\(b\\.?s\\.?\\))?$',\n",
    "    r'^bachelor of arts(\\s*\\(b\\.?a\\.?\\))?$',\n",
    "    r'^bachelors$'\n",
    "]\n",
    "\n",
    "# Create a pattern that matches any of the generic patterns (case insensitive)\n",
    "generic_pattern = '|'.join([f'({pattern})' for pattern in generic_patterns])\n",
    "\n",
    "# Count rows before filtering\n",
    "rows_before = len(graduates_person_level)\n",
    "\n",
    "# Filter out rows with generic degree descriptions\n",
    "graduates_person_level = graduates_person_level[\n",
    "    ~graduates_person_level['university_major_raw'].str.lower().str.strip().str.match(generic_pattern, na=False)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rows_after = len(graduates_person_level)\n",
    "print(f\"Removed {rows_before - rows_after:,} rows with generic degree descriptions\")\n",
    "print(f\"Remaining rows: {rows_after:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean university_major_raw by removing generic degree prefixes\n",
    "import re\n",
    "\n",
    "# Patterns to remove from the beginning of university_major_raw text\n",
    "patterns_to_remove = [\n",
    "    r'^bachelor of (applied\\s+)?science(\\s*\\(b\\.?s\\.?\\))?\\s*,?\\s*',\n",
    "    r'^bachelor of arts(\\s*\\(b\\.?a\\.?\\))?\\s*,?\\s*',\n",
    "    r'^bachelor\\'?s? degree\\w?,']\n",
    "\n",
    "# Combine all patterns\n",
    "combined_pattern = '|'.join(patterns_to_remove)\n",
    "\n",
    "\n",
    "# Apply cleaning (case insensitive)\n",
    "graduates_person_level['university_major_clean'] = graduates_person_level['university_major_raw'].str.replace(\n",
    "    combined_pattern, '', case=False, regex=True\n",
    ").str.strip()\n",
    "\n",
    "graduates_person_level['university_major_clean'] = (\n",
    "    graduates_person_level['university_major_clean']\n",
    "    .str.replace(r'\\b[Mm]inor\\b[ \\w]*', '', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Remove entries that are just short parenthetical notes (e.g., \"(BA)\", \"(BS)\")\n",
    "graduates_person_level = graduates_person_level[~graduates_person_level['university_major_clean'].str.contains(r'^\\(.{0:6}\\)$')]\n",
    "print(f\"\\nAfter cleaning - sample of university_major_raw:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad38b27",
   "metadata": {},
   "source": [
    "#### 2.4.2 Define the major categorization  keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29098654",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  ['asian', 'hispanic', 'african','latin american','gender','feminist','asian american', 'african american','frech','russian','middle eastern','european','caribbean','women\\'s','chicano','jewish']\n",
    "studies_groups_social_science  = [g + ' studies' for g in x]\n",
    "\n",
    "majors_categories = {\n",
    "    \"Engineering or Computer\": {\"keywords\": ['engineering', 'computer', 'software', 'electronic', 'information systems', 'information technology', 'informatics', 'robotics', 'machine learning', 'artificial intelligence', 'cybersecurity',\n",
    "                            'architecture', 'urban planning'],\n",
    "                               \"variable_name\":\"engineering_or_computer\"},\n",
    "    \"Natural Science\": {\"keywords\": ['biology', 'biological', 'chemistry', 'physics', 'environmental', 'geology', 'earth', 'astronomy', 'astrophysics', 'meteorology', 'biotechnology', 'biochemistry', 'biotech', 'biochem', 'neuroscience', 'marine', 'oceanography', 'ecology', 'genetics'],\n",
    "                       \"variable_name\":\"natural_science\"},\n",
    "    \"Math\": {\"keywords\": ['math', 'mathematics', 'statistics', 'statistical', 'stats', 'data science', 'analytics'],\n",
    "             \"variable_name\":\"math\"},\n",
    "    \"Education\": {\"keywords\": ['education', 'teacher', 'teaching', 'instructional', 'curriculum', 'pedagogy', 'educational','speech therapy'],\n",
    "                  \"variable_name\":\"education\"},\n",
    "    \"Clinical Work\": {\"keywords\": ['social work', 'pre-med', 'pharmacy', 'nursing', 'health', 'mental', 'therapy', 'clinical', 'counseling'],\n",
    "                      \"variable_name\":\"clinical_work\"},\n",
    "    \"Law / Climinology\": {\"keywords\": ['law', 'legal', 'criminology', 'criminal', 'justice', 'landscape'],\n",
    "                          \"variable_name\":\"law_climinology\"},\n",
    "    \"Economics and Finance\": {\"keywords\": ['economics', 'econ', 'finance', 'financial', 'banking', 'investment', 'econometrics'],\n",
    "                              \"variable_name\":\"economics_and_finance\"},\n",
    "    \"Business (not Economics / Finance)\": {\"keywords\": ['public relations','business', 'management', 'accounting', 'marketing', 'public relations', 'administration', 'advertising', 'human resources', 'operations', 'supply chain', 'organizational behavior'],\n",
    "                                           \"variable_name\":\"business_not_economics_finance\"},\n",
    "    \"Social Science (not Economics)\": {\"keywords\": (['social science', 'history', 'sociology', 'anthropology', 'international relations', 'political science', 'government',\n",
    "                                                   'policy',  'ethnic', 'cultural', 'religion', 'philosophy','liberal art'] + \n",
    "                                studies_groups_social_science)\n",
    "                                ,\"variable_name\":\"social_science_not_economics\"}\n",
    "                               ,\n",
    "    \"Arts\": {\"keywords\": ['fine art', 'design', 'graphic', 'music', 'theater', 'film', 'cinema', 'photography', 'fashion', 'visual', 'dance', 'performing'],\n",
    "              \"variable_name\":\"arts\"},\n",
    "    \"Communications\": {\"keywords\": ['communication', 'communications', 'media', 'journalism', 'broadcasting'],\n",
    "                      \"variable_name\":\"communications\"},\n",
    "    \"English\": {\"keywords\": ['english', 'literature', 'writing'],\n",
    "                \"variable_name\":\"english\"},\n",
    "    \"Psychology\": {\"keywords\": ['psychology'],\n",
    "                   \"variable_name\":\"psychology\"}\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbfa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle =graduates_person_level['university_major_clean'].dropna().astype(str).sample(100, random_state=42).tolist()[1]\n",
    "\n",
    "print(f\"subtitle: {subtitle}\")\n",
    "subtitle_lower = subtitle.lower()\n",
    "for major, keywords in majors_categories.items():\n",
    "    for keyword in keywords:\n",
    "        if keyword in subtitle_lower:\n",
    "            print(f\"major: {major}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c9165",
   "metadata": {},
   "source": [
    "#### 2.4.3 Run algorithm to categorize majors based on keywords, takes 10 mins or so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaaa14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Assign major group to each observation in coresignal_member_education\n",
    "def assign_major(subtitle, majors_categories):\n",
    "    if pd.isna(subtitle):\n",
    "        return None\n",
    "\n",
    "    subtitle_lower = subtitle.lower()\n",
    "    for major in majors_categories.keys():\n",
    "        keywords = majors_categories[major][\"keywords\"]\n",
    "        for keyword in keywords:\n",
    "            if keyword in subtitle_lower:\n",
    "                return (major, \"major_\" + majors_categories[major][\"variable_name\"])\n",
    "    return ('Other', 'major_other')\n",
    "\n",
    "print(\"Applying major assignment to the dataset...\")\n",
    "\n",
    "# Apply the assign_major function and extract results\n",
    "major_results = graduates_person_level['university_major_clean'].progress_apply(\n",
    "    lambda x: assign_major(x, majors_categories)\n",
    ")\n",
    "\n",
    "# Extract the major categories and variable names\n",
    "major_categories = [result[0] if result else 'Other' for result in major_results]\n",
    "major_variables = [result[1] if result else 'major_other' for result in major_results]\n",
    "\n",
    "# Create university_major_categorized by joining multiple categories with semicolons\n",
    "graduates_person_level['university_major_categorized'] = [\n",
    "    '; '.join(sorted(set(cat.split('; ')))) if cat else 'Other' \n",
    "    for cat in major_categories\n",
    "]\n",
    "\n",
    "# Create dummy variables for each major category\n",
    "for major_category, details in majors_categories.items():\n",
    "    var_name = f\"major_{details['variable_name']}\"\n",
    "    graduates_person_level[var_name] = [\n",
    "        1 if var_name in str(major_var) else 0 \n",
    "        for major_var in major_variables\n",
    "    ]\n",
    "\n",
    "# Add major_other dummy variable\n",
    "graduates_person_level['major_other'] = [\n",
    "    1 if major_var == 'major_other' else 0 \n",
    "    for major_var in major_variables\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379f770",
   "metadata": {},
   "source": [
    "## 2.5 Create the cofounder dataset only of cofounding events with same url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a8dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graduates_with_education_job_level from pickle...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/shared/share_scp/coresignal')\n",
    "\n",
    "# Load graduates with education job level data if not already in memory\n",
    "if 'graduates_with_education_job_levelx' not in globals():\n",
    "    print(\"Loading graduates_with_education_job_level from pickle...\")\n",
    "    graduates_with_education_job_levelx = pd.read_pickle('graduates_with_education_job_level_latest.pkl')\n",
    "else:\n",
    "    print(\"graduates_with_education_job_level already in memory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45d47e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "founders_with_education = graduates_with_education_job_levelx[graduates_with_education_job_levelx['is_founder_or_owner_with_url']].copy()\n",
    "del graduates_with_education_job_levelx\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf0a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows with company_url and member_id:\n",
      "                                            company_url  member_id\n",
      "345   https://www.linkedin.com/company/unleash-the-a...   84468968\n",
      "346   https://www.linkedin.com/company/unleash-the-a...   84468968\n",
      "1341  https://ie.linkedin.com/company/core-investmen...   84477973\n",
      "1342  https://ie.linkedin.com/company/core-investmen...   84477973\n",
      "1698        https://www.linkedin.com/company/zwick-post   84480828\n",
      "\n",
      "Unique companies: 205553\n",
      "Unique members: 72758\n",
      "company_url dtype: category\n",
      "member_id dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the relevant columns for our task\n",
    "print(f\"First few rows with company_url and member_id:\")\n",
    "print(founders_with_education[['company_url', 'member_id']].head())\n",
    "print(f\"\\nUnique companies: {founders_with_education['company_url'].nunique()}\")\n",
    "print(f\"Unique members: {founders_with_education['member_id'].nunique()}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"company_url dtype: {founders_with_education['company_url'].dtype}\")\n",
    "print(f\"member_id dtype: {founders_with_education['member_id'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd78b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating aggregation of unique member_ids by company_url...\n",
      "Aggregation completed. Shape: (205553, 2)\n",
      "Sample of aggregation:\n",
      "                                         company_url  unique_member_count\n",
      "0  https://ad.linkedin.com/company/11th-orchard-b...                    1\n",
      "1  https://ad.linkedin.com/company/1st-assured-ba...                    1\n",
      "2      https://ad.linkedin.com/company/2girl-roaster                    1\n",
      "3  https://ad.linkedin.com/company/313-consulting...                    1\n",
      "4             https://ad.linkedin.com/company/502ads                    1\n",
      "\n",
      "Distribution of unique member counts:\n",
      "count    205553.000000\n",
      "mean          1.046572\n",
      "std           1.068705\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max         250.000000\n",
      "Name: unique_member_count, dtype: float64\n",
      "Aggregation completed. Shape: (205553, 2)\n",
      "Sample of aggregation:\n",
      "                                         company_url  unique_member_count\n",
      "0  https://ad.linkedin.com/company/11th-orchard-b...                    1\n",
      "1  https://ad.linkedin.com/company/1st-assured-ba...                    1\n",
      "2      https://ad.linkedin.com/company/2girl-roaster                    1\n",
      "3  https://ad.linkedin.com/company/313-consulting...                    1\n",
      "4             https://ad.linkedin.com/company/502ads                    1\n",
      "\n",
      "Distribution of unique member counts:\n",
      "count    205553.000000\n",
      "mean          1.046572\n",
      "std           1.068705\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max         250.000000\n",
      "Name: unique_member_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create aggregation of unique member_ids by company_url\n",
    "print(\"Creating aggregation of unique member_ids by company_url...\")\n",
    "\n",
    "# Since company_url is categorical, use observed=True to avoid empty categories\n",
    "unique_members_by_company = founders_with_education.groupby('company_url', observed=True)['member_id'].nunique().reset_index()\n",
    "unique_members_by_company.columns = ['company_url', 'unique_member_count']\n",
    "\n",
    "print(f\"Aggregation completed. Shape: {unique_members_by_company.shape}\")\n",
    "print(f\"Sample of aggregation:\")\n",
    "print(unique_members_by_company.head())\n",
    "print(f\"\\nDistribution of unique member counts:\")\n",
    "print(unique_members_by_company['unique_member_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de95f3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding unique_member_count column to graduates_with_education_job_level...\n",
      "Merge completed. New shape: (678597, 46)\n",
      "New columns: ['levenshtein_distance', 'is_duplicated', 'worked_as_engineer', 'worked_in_sales', 'unique_member_count']\n",
      "\n",
      "Unique member count statistics:\n",
      "count    678597.000000\n",
      "mean          2.305970\n",
      "std          13.310874\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max         250.000000\n",
      "Name: unique_member_count, dtype: float64\n",
      "\n",
      "Sample of data with new column:\n",
      "                                         company_url  member_id  \\\n",
      "0  https://www.linkedin.com/company/unleash-the-a...   84468968   \n",
      "1  https://www.linkedin.com/company/unleash-the-a...   84468968   \n",
      "2  https://ie.linkedin.com/company/core-investmen...   84477973   \n",
      "3  https://ie.linkedin.com/company/core-investmen...   84477973   \n",
      "4        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "5        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "6        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "7        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "8    https://ca.linkedin.com/company/stone-table-llc  202023882   \n",
      "9   https://www.linkedin.com/company/stone-table-llc  202023882   \n",
      "\n",
      "   unique_member_count  \n",
      "0                    1  \n",
      "1                    1  \n",
      "2                    1  \n",
      "3                    1  \n",
      "4                    1  \n",
      "5                    1  \n",
      "6                    1  \n",
      "7                    1  \n",
      "8                    1  \n",
      "9                    1  \n",
      "Merge completed. New shape: (678597, 46)\n",
      "New columns: ['levenshtein_distance', 'is_duplicated', 'worked_as_engineer', 'worked_in_sales', 'unique_member_count']\n",
      "\n",
      "Unique member count statistics:\n",
      "count    678597.000000\n",
      "mean          2.305970\n",
      "std          13.310874\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max         250.000000\n",
      "Name: unique_member_count, dtype: float64\n",
      "\n",
      "Sample of data with new column:\n",
      "                                         company_url  member_id  \\\n",
      "0  https://www.linkedin.com/company/unleash-the-a...   84468968   \n",
      "1  https://www.linkedin.com/company/unleash-the-a...   84468968   \n",
      "2  https://ie.linkedin.com/company/core-investmen...   84477973   \n",
      "3  https://ie.linkedin.com/company/core-investmen...   84477973   \n",
      "4        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "5        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "6        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "7        https://www.linkedin.com/company/zwick-post   84480828   \n",
      "8    https://ca.linkedin.com/company/stone-table-llc  202023882   \n",
      "9   https://www.linkedin.com/company/stone-table-llc  202023882   \n",
      "\n",
      "   unique_member_count  \n",
      "0                    1  \n",
      "1                    1  \n",
      "2                    1  \n",
      "3                    1  \n",
      "4                    1  \n",
      "5                    1  \n",
      "6                    1  \n",
      "7                    1  \n",
      "8                    1  \n",
      "9                    1  \n"
     ]
    }
   ],
   "source": [
    "# Add the unique member count column to graduates_with_education_job_level\n",
    "print(\"Adding unique_member_count column to graduates_with_education_job_level...\")\n",
    "\n",
    "# Merge the aggregation back to the main dataframe\n",
    "founders_with_education = founders_with_education.merge(\n",
    "    unique_members_by_company, \n",
    "    on='company_url', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merge completed. New shape: {founders_with_education.shape}\")\n",
    "print(f\"New columns: {founders_with_education.columns.tolist()[-5:]}\")  # Show last 5 columns\n",
    "\n",
    "# Verify the new column\n",
    "print(f\"\\nUnique member count statistics:\")\n",
    "print(founders_with_education['unique_member_count'].describe())\n",
    "print(f\"\\nSample of data with new column:\")\n",
    "print(founders_with_education[['company_url', 'member_id', 'unique_member_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295b7846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICATION ===\n",
      "Total rows in dataframe: 678,597\n",
      "Rows with non-null unique_member_count: 678,597\n",
      "Rows with null unique_member_count: 0\n",
      "\n",
      "Examples of companies with different unique member counts:\n",
      "Top 5 companies by unique member count:\n",
      "company_url\n",
      "https://www.linkedin.com/company/farmers-insurance                   250\n",
      "https://www.linkedin.com/company/farmers-insurance?trk=ppro_cprof    212\n",
      "https://www.linkedin.com/company/allstate                            142\n",
      "https://www.linkedin.com/company/allstate?trk=ppro_cprof             112\n",
      "https://www.linkedin.com/company/state_farm                          104\n",
      "Name: unique_member_count, dtype: int64\n",
      "\n",
      "Bottom 5 companies by unique member count:\n",
      "company_url\n",
      "https://ng.linkedin.com/company/arts-administrators-of-color-network    1\n",
      "https://ng.linkedin.com/company/arty-barty-creations                    1\n",
      "https://ng.linkedin.com/company/asarasi-inc-                            1\n",
      "https://ng.linkedin.com/company/ashley-mckinney-interior-design-llc     1\n",
      "https://ng.linkedin.com/company/aria-integrative-medicine               1\n",
      "Name: unique_member_count, dtype: int64\n",
      "\n",
      "=== SPOT CHECK ===\n",
      "Test company: https://www.linkedin.com/company/amway\n",
      "Actual unique members: 51\n",
      "Reported unique members: 51\n",
      "Match: True\n",
      "Top 5 companies by unique member count:\n",
      "company_url\n",
      "https://www.linkedin.com/company/farmers-insurance                   250\n",
      "https://www.linkedin.com/company/farmers-insurance?trk=ppro_cprof    212\n",
      "https://www.linkedin.com/company/allstate                            142\n",
      "https://www.linkedin.com/company/allstate?trk=ppro_cprof             112\n",
      "https://www.linkedin.com/company/state_farm                          104\n",
      "Name: unique_member_count, dtype: int64\n",
      "\n",
      "Bottom 5 companies by unique member count:\n",
      "company_url\n",
      "https://ng.linkedin.com/company/arts-administrators-of-color-network    1\n",
      "https://ng.linkedin.com/company/arty-barty-creations                    1\n",
      "https://ng.linkedin.com/company/asarasi-inc-                            1\n",
      "https://ng.linkedin.com/company/ashley-mckinney-interior-design-llc     1\n",
      "https://ng.linkedin.com/company/aria-integrative-medicine               1\n",
      "Name: unique_member_count, dtype: int64\n",
      "\n",
      "=== SPOT CHECK ===\n",
      "Test company: https://www.linkedin.com/company/amway\n",
      "Actual unique members: 51\n",
      "Reported unique members: 51\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Final verification of the new column\n",
    "print(\"=== VERIFICATION ===\")\n",
    "print(f\"Total rows in dataframe: {len(founders_with_education):,}\")\n",
    "print(f\"Rows with non-null unique_member_count: {founders_with_education['unique_member_count'].notna().sum():,}\")\n",
    "print(f\"Rows with null unique_member_count: {founders_with_education['unique_member_count'].isna().sum():,}\")\n",
    "\n",
    "# Check some specific examples\n",
    "print(f\"\\nExamples of companies with different unique member counts:\")\n",
    "sample_companies = founders_with_education.groupby('company_url', observed=True)['unique_member_count'].first().sort_values(ascending=False)\n",
    "print(f\"Top 5 companies by unique member count:\")\n",
    "print(sample_companies.head())\n",
    "print(f\"\\nBottom 5 companies by unique member count:\")\n",
    "print(sample_companies.tail())\n",
    "\n",
    "# Verify the calculation is correct for a few companies\n",
    "print(f\"\\n=== SPOT CHECK ===\")\n",
    "test_company = sample_companies.index[10]  # Pick a company in the middle\n",
    "actual_count = founders_with_education[founders_with_education['company_url'] == test_company]['member_id'].nunique()\n",
    "reported_count = founders_with_education[founders_with_education['company_url'] == test_company]['unique_member_count'].iloc[0]\n",
    "print(f\"Test company: {test_company}\")\n",
    "print(f\"Actual unique members: {actual_count}\")\n",
    "print(f\"Reported unique members: {reported_count}\")\n",
    "print(f\"Match: {actual_count == reported_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2b83f",
   "metadata": {},
   "source": [
    "notes \n",
    "\n",
    "--- only keeping those with 8 co-founders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "048595b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cofounders_urls = founders_with_education[founders_with_education['unique_member_count'].between(2, 9)]['company_url']\n",
    "mask = founders_with_education.company_url.isin(cofounders_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f53e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cofounder/coowner events: 40,849\n",
      "Cofounder events dataset saved.\n",
      "Cofounder events dataset saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create cofounder_events dataset\n",
    "cofounder_events = founders_with_education[mask].copy()\n",
    "print(f\"Total cofounder/coowner events: {len(cofounder_events):,}\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "cofounder_events.rename(columns=   {'year_from': 'year_start_college',\n",
    "    'year_to': 'year_end_college',\n",
    "    'member_id': 'linkedin_member_id',\n",
    "    'title_education': 'university_title',\n",
    "    'subtitle': 'university_major_raw',\n",
    "    'date_from_experience': 'start_founder_date',\n",
    "    'date_to_experience': 'end_founder_date',\n",
    "    'member_id': 'linkedin_member_id',}, inplace=True)\n",
    "\n",
    "# Select relevant columns for cofounder dataset\n",
    "cofounder_dataset_columns = [\n",
    "    'linkedin_member_id', 'company_name', 'company_url', 'title_experience', 'start_founder_date', 'end_founder_date',\n",
    "    'year_start_college', 'year_end_college', 'university_title',\n",
    "    'unitid'\n",
    "]\n",
    "\n",
    "cofounder_events = cofounder_events[cofounder_dataset_columns]\n",
    "cofounder_events.to_pickle('cofounder_events_latest.pkl')\n",
    "print(\"Cofounder events dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597ad11",
   "metadata": {},
   "source": [
    "## 2.6 Data testing and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd78bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of graduates: {graduates_person_level.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae455f",
   "metadata": {},
   "source": [
    "## 2.7 Report summary statistics of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for all major categories\n",
    "print(\"Summary Statistics for Major Categories:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate percentages for each major category\n",
    "total_graduates = len(graduates_person_level)\n",
    "print(f\"Total graduates: {total_graduates:,}\")\n",
    "print()\n",
    "\n",
    "# Print statistics for each major category dummy variable\n",
    "major_dummy_cols = [col for col in graduates_person_level.columns if col.startswith('major_')]\n",
    "for col in major_dummy_cols:\n",
    "    count = graduates_person_level[col].sum()\n",
    "    percentage = (count / total_graduates) * 100\n",
    "    print(f\"{col:<35}: {count:>8,} ({percentage:>5.1f}%)\")\n",
    "\n",
    "print()\n",
    "print(\"University Major Categorized Distribution:\")\n",
    "print(\"-\" * 45)\n",
    "major_dist = graduates_person_level['university_major_categorized'].value_counts()\n",
    "for category, count in major_dist.items():\n",
    "    percentage = (count / total_graduates) * 100\n",
    "    print(f\"{category:<35}: {count:>8,} ({percentage:>5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa02e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graduates_person_level.sample(5000)[['university_major_raw','university_major_clean','university_major_categorized']].to_csv('graduates_person_level_majors_sample5000.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d9f6f",
   "metadata": {},
   "source": [
    "# 3 Store files for Stata analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4968e4de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graduates_person_level' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m      2\u001b[39m variable_labels = {\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Core Identification Variables\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlinkedin_member_id\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mUnique LinkedIn member identifier\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mworked_in_sales_10_years\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mWorked in sales role within 10 years\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     80\u001b[39m }\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Add labels as metadata to the DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[43mgraduates_person_level\u001b[49m.attrs[\u001b[33m'\u001b[39m\u001b[33mvariable_labels\u001b[39m\u001b[33m'\u001b[39m] = variable_labels\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Display how many variables have labels\u001b[39;00m\n\u001b[32m     86\u001b[39m labeled_vars = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m graduates_person_level.columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m variable_labels]\n",
      "\u001b[31mNameError\u001b[39m: name 'graduates_person_level' is not defined"
     ]
    }
   ],
   "source": [
    "# Create variable labels dictionary for Stata export\n",
    "variable_labels = {\n",
    "    # Core Identification Variables\n",
    "    'linkedin_member_id': 'Unique LinkedIn member identifier',\n",
    "    'unitid': 'University identification code from IPEDS database',\n",
    "    \n",
    "    # Educational Background Variables\n",
    "    'university_title': 'Official name of the university',\n",
    "    'university_major_raw': 'Raw major/degree description as reported',\n",
    "    'university_major_clean': 'Cleaned major description with degree prefixes removed',\n",
    "    'university_major_categorized': 'Major classified into standardized categories',\n",
    "    'year_start_college': 'Year the individual started college',\n",
    "    'year_end_college': 'Year the individual graduated from college',\n",
    "    \n",
    "    # Major Category Dummy Variables\n",
    "    'major_engineering_or_computer': 'Engineering, computer science, software, IT, robotics, AI',\n",
    "    'major_natural_science': 'Biology, chemistry, physics, environmental science, geology',\n",
    "    'major_math': 'Mathematics, statistics, data science, analytics',\n",
    "    'major_education': 'Education, teaching, instructional design, curriculum',\n",
    "    'major_clinical_work': 'Social work, pre-med, pharmacy, nursing, health, therapy',\n",
    "    'major_law_climinology': 'Law, legal studies, criminology, criminal justice',\n",
    "    'major_economics_and_finance': 'Economics, finance, banking, investment, econometrics',\n",
    "    'major_business_not_economics_finance': 'Business, management, accounting, marketing, PR, admin',\n",
    "    'major_social_science_not_economics': 'History, sociology, anthropology, political science',\n",
    "    'major_arts': 'Fine arts, design, music, theater, film, photography',\n",
    "    'major_communications': 'Communications, media, journalism, broadcasting',\n",
    "    'major_english': 'English, literature, writing',\n",
    "    'major_psychology': 'Psychology',\n",
    "    'major_other': 'All other majors not categorized above',\n",
    "    \n",
    "    # 3-Year Entrepreneurship Variables\n",
    "    'is_founder_only_3_years': 'Founded company within 3 years (title contains founder)',\n",
    "    'is_owner_only_3_years': 'Owned company within 3 years (title contains owner)',\n",
    "    'is_founder_or_owner_3_years': 'Founded or owned company within 3 years',\n",
    "    'is_cofounder_or_coowner_title_3_years': 'Co-founded or co-owned company within 3 years',\n",
    "    'is_cofounder_only_title_3_years': 'Co-founded company within 3 years',\n",
    "    'is_coowner_only_title_3_years': 'Co-owned company within 3 years',\n",
    "    'is_founder_or_owner_with_url_3_years': 'Founded/owned company with LinkedIn URL within 3 years',\n",
    "    'is_founder_or_owner_inc_3_years': 'Founded/owned incorporated company within 3 years',\n",
    "    'cofound_coown_same_url_3_years': 'Co-founded/co-owned company (same URL) within 3 years',\n",
    "    'cofound_coown_same_url_num_schools_3_years': 'Number different universities among co-founders within 3 years',\n",
    "    'cofound_coown_same_url_same_school_3_years': 'Co-founded with same university graduate within 3 years',\n",
    "    'cofound_coown_same_url_diff_school_3_years': 'Co-founded with different university graduate within 3 years',\n",
    "    \n",
    "    # 5-Year Entrepreneurship Variables\n",
    "    'is_founder_only_5_years': 'Founded company within 5 years (title contains founder)',\n",
    "    'is_owner_only_5_years': 'Owned company within 5 years (title contains owner)',\n",
    "    'is_founder_or_owner_5_years': 'Founded or owned company within 5 years',\n",
    "    'is_cofounder_or_coowner_title_5_years': 'Co-founded or co-owned company within 5 years',\n",
    "    'is_cofounder_only_title_5_years': 'Co-founded company within 5 years',\n",
    "    'is_coowner_only_title_5_years': 'Co-owned company within 5 years',\n",
    "    'is_founder_or_owner_with_url_5_years': 'Founded/owned company with LinkedIn URL within 5 years',\n",
    "    'is_founder_or_owner_inc_5_years': 'Founded/owned incorporated company within 5 years',\n",
    "    'cofound_coown_same_url_5_years': 'Co-founded/co-owned company (same URL) within 5 years',\n",
    "    'cofound_coown_same_url_num_schools_5_years': 'Number different universities among co-founders within 5 years',\n",
    "    'cofound_coown_same_url_same_school_5_years': 'Co-founded with same university graduate within 5 years',\n",
    "    'cofound_coown_same_url_diff_school_5_years': 'Co-founded with different university graduate within 5 years',\n",
    "    \n",
    "    # 10-Year Entrepreneurship Variables\n",
    "    'is_founder_only_10_years': 'Founded company within 10 years (title contains founder)',\n",
    "    'is_owner_only_10_years': 'Owned company within 10 years (title contains owner)',\n",
    "    'is_founder_or_owner_10_years': 'Founded or owned company within 10 years',\n",
    "    'is_cofounder_or_coowner_title_10_years': 'Co-founded or co-owned company within 10 years',\n",
    "    'is_cofounder_only_title_10_years': 'Co-founded company within 10 years',\n",
    "    'is_coowner_only_title_10_years': 'Co-owned company within 10 years',\n",
    "    'is_founder_or_owner_with_url_10_years': 'Founded/owned company with LinkedIn URL within 10 years',\n",
    "    'is_founder_or_owner_inc_10_years': 'Founded/owned incorporated company within 10 years',\n",
    "    'cofound_coown_same_url_10_years': 'Co-founded/co-owned company (same URL) within 10 years',\n",
    "    'cofound_coown_same_url_num_schools_10_years': 'Number different universities among co-founders within 10 years',\n",
    "    'cofound_coown_same_url_same_school_10_years': 'Co-founded with same university graduate within 10 years',\n",
    "    'cofound_coown_same_url_diff_school_10_years': 'Co-founded with different university graduate within 10 years',\n",
    "    \n",
    "    # Career Experience Variables\n",
    "    'worked_as_engineer_3_years': 'Worked in engineering role within 3 years',\n",
    "    'worked_as_engineer_5_years': 'Worked in engineering role within 5 years',\n",
    "    'worked_as_engineer_10_years': 'Worked in engineering role within 10 years',\n",
    "    'worked_in_sales_3_years': 'Worked in sales role within 3 years',\n",
    "    'worked_in_sales_5_years': 'Worked in sales role within 5 years',\n",
    "    'worked_in_sales_10_years': 'Worked in sales role within 10 years'\n",
    "}\n",
    "\n",
    "# Add labels as metadata to the DataFrame\n",
    "graduates_person_level.attrs['variable_labels'] = variable_labels\n",
    "\n",
    "# Display how many variables have labels\n",
    "labeled_vars = [col for col in graduates_person_level.columns if col in variable_labels]\n",
    "unlabeled_vars = [col for col in graduates_person_level.columns if col not in variable_labels]\n",
    "\n",
    "print(f\"Variables with labels: {len(labeled_vars)}\")\n",
    "print(f\"Variables without labels: {len(unlabeled_vars)}\")\n",
    "\n",
    "if unlabeled_vars:\n",
    "    print(f\"\\nUnlabeled variables: {unlabeled_vars}\")\n",
    "    \n",
    "print(f\"\\nTotal variables in dataset: {len(graduates_person_level.columns)}\")\n",
    "print(f\"Sample of labeled variables:\")\n",
    "for i, (var, label) in enumerate(list(variable_labels.items())[:5]):\n",
    "    print(f\"  {var}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a3470",
   "metadata": {
    "tags": [
     "scratch"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "#Scratch\n",
    "#graduates_person_level = pd.read_stata(\"graduates_person_level_091182025.dta\")\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(graduates_person_level.year_start_college.value_counts().sort_index())\n",
    "\n",
    "# Add: subtitle to a cleaned major\n",
    "# Founded within years: finer from 1 to 10 years, every year -- make count per year, not cumulative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aef1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Each row is one person\n",
    "# University that they went to --> well matched into a single ID using Runjing's data.\n",
    "\n",
    "# Start and end year and montyh of bachelor's degree\n",
    "     # would be cool to show collaboration across groups. \n",
    "\n",
    "# Do they start a firm within 3, 5, or 10 years\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Separate dataset of founding events: person id, firm id, founding date, location of firm. \n",
    "\n",
    "print(\"Storing graduates_person_level\", flush=True)\n",
    "#graduates_person_level = graduates_person_level[~graduates_person_level.linkedin_member_id.duplicated() ]\n",
    "graduates_person_level.to_stata(\"graduates_person_level_10082025.dta\",  version=118)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61292c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(graduates_person_level.describe(include='all').transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2033e37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9dd5aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable labels to be included in Stata file:\n",
      "linkedin_member_id: LinkedIn Member Unique Identifier\n",
      "company_name: Company Name\n",
      "company_url: Company LinkedIn URL\n",
      "title_experience: Job Title/Experience Title\n",
      "start_founder_date: Start Date of Founder Position (Original)\n",
      "end_founder_date: End Date of Founder Position (Original)\n",
      "year_start_college: College/University Start Year\n",
      "year_end_college: College/University End Year\n",
      "university_title: University/College Name\n",
      "unitid: University Unit ID (IPEDS)\n",
      "start_founder_year: Start Year of Founder Position (Extracted)\n",
      "end_founder_year: End Year of Founder Position (Extracted)\n"
     ]
    }
   ],
   "source": [
    "cofounder_events = pd.read_pickle('cofounder_events_latest.pkl')\n",
    "columns =  ['linkedin_member_id', 'company_name', 'company_url', 'title_experience', 'start_founder_date', 'end_founder_date',\n",
    "    'year_start_college', 'year_end_college', 'university_title',\n",
    "    'unitid']\n",
    "cofounder_events = cofounder_events[columns]\n",
    "\n",
    "cofounder_events['start_founder_year'] = cofounder_events['start_founder_date'].str.extract(r'(\\d{4})').astype('Int64')\n",
    "cofounder_events['end_founder_year'] = cofounder_events['end_founder_date'].str.extract(r'(\\d{4})').astype('Int64')\n",
    "\n",
    "# Define variable labels for Stata export\n",
    "variable_labels = {\n",
    "    'linkedin_member_id': 'LinkedIn Member Unique Identifier',\n",
    "    'company_name': 'Company Name',\n",
    "    'company_url': 'Company LinkedIn URL',\n",
    "    'title_experience': 'Job Title/Experience Title',\n",
    "    'start_founder_date': 'Start Date of Founder Position (Original)',\n",
    "    'end_founder_date': 'End Date of Founder Position (Original)',\n",
    "    'year_start_college': 'College/University Start Year',\n",
    "    'year_end_college': 'College/University End Year',\n",
    "    'university_title': 'University/College Name',\n",
    "    'unitid': 'University Unit ID (IPEDS)',\n",
    "    'start_founder_year': 'Start Year of Founder Position (Extracted)',\n",
    "    'end_founder_year': 'End Year of Founder Position (Extracted)'\n",
    "}\n",
    "\n",
    "# Print the labels for verification\n",
    "print(\"Variable labels to be included in Stata file:\")\n",
    "for var, label in variable_labels.items():\n",
    "    print(f\"{var}: {label}\")\n",
    "\n",
    "# Convert categorical columns to object type to avoid Stata value label issues\n",
    "cofounder_events_export = cofounder_events.copy()\n",
    "for col in cofounder_events_export.columns:\n",
    "    if cofounder_events_export[col].dtype.name == 'category':\n",
    "        cofounder_events_export[col] = cofounder_events_export[col].astype(str)\n",
    "\n",
    "cofounder_events_export.to_stata(\"cofounder_events_11132025.dta\", version=118, variable_labels=variable_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b746f4",
   "metadata": {},
   "source": [
    "## Summary Statistics for graduates_person_level Dataset\n",
    "\n",
    "Comprehensive overview of the dataset structure and variable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Dataset shape: {graduates_person_level.shape}\")\n",
    "print(f\"Number of observations: {graduates_person_level.shape[0]:,}\")\n",
    "print(f\"Number of variables: {graduates_person_level.shape[1]:,}\")\n",
    "print(f\"Memory usage: {graduates_person_level.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nData types:\")\n",
    "print(graduates_person_level.dtypes.value_counts())\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b138d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"=== MISSING VALUES ANALYSIS ===\")\n",
    "missing_summary = graduates_person_level.isnull().sum()\n",
    "missing_percentage = (missing_summary / len(graduates_person_level)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Variable': missing_summary.index,\n",
    "    'Missing_Count': missing_summary.values,\n",
    "    'Missing_Percentage': missing_percentage.values\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"Variables with missing values: {(missing_df['Missing_Count'] > 0).sum()}\")\n",
    "print(f\"Variables with no missing values: {(missing_df['Missing_Count'] == 0).sum()}\")\n",
    "print(\"\\nTop 20 variables with highest missing values:\")\n",
    "print(missing_df.head(20).to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Numeric variables summary statistics\n",
    "print(\"=== NUMERIC VARIABLES SUMMARY ===\")\n",
    "numeric_cols = graduates_person_level.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Number of numeric variables: {len(numeric_cols)}\")\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    numeric_summary = graduates_person_level[numeric_cols].describe()\n",
    "    print(\"\\nDetailed summary statistics for numeric variables:\")\n",
    "    print(numeric_summary.round(3))\n",
    "    \n",
    "    # Additional statistics for numeric variables\n",
    "    print(\"\\nAdditional numeric statistics:\")\n",
    "    additional_stats = pd.DataFrame({\n",
    "        'Variable': numeric_cols,\n",
    "        'Median': graduates_person_level[numeric_cols].median(),\n",
    "        'Mode': graduates_person_level[numeric_cols].mode().iloc[0] if len(graduates_person_level[numeric_cols].mode()) > 0 else np.nan,\n",
    "        'Variance': graduates_person_level[numeric_cols].var(),\n",
    "        'Skewness': graduates_person_level[numeric_cols].skew(),\n",
    "        'Kurtosis': graduates_person_level[numeric_cols].kurtosis()\n",
    "    }).round(3)\n",
    "    print(additional_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables summary\n",
    "print(\"=== CATEGORICAL VARIABLES SUMMARY ===\")\n",
    "categorical_cols = graduates_person_level.select_dtypes(include=['object', 'category']).columns\n",
    "print(f\"Number of categorical variables: {len(categorical_cols)}\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"\\nCategorical variables overview:\")\n",
    "    cat_summary = []\n",
    "    for col in categorical_cols:\n",
    "        unique_count = graduates_person_level[col].nunique()\n",
    "        most_frequent = graduates_person_level[col].mode().iloc[0] if len(graduates_person_level[col].mode()) > 0 else 'N/A'\n",
    "        most_frequent_count = graduates_person_level[col].value_counts().iloc[0] if len(graduates_person_level[col].value_counts()) > 0 else 0\n",
    "        \n",
    "        cat_summary.append({\n",
    "            'Variable': col,\n",
    "            'Unique_Values': unique_count,\n",
    "            'Most_Frequent': str(most_frequent)[:50] + ('...' if len(str(most_frequent)) > 50 else ''),\n",
    "            'Most_Frequent_Count': most_frequent_count,\n",
    "            'Most_Frequent_Pct': (most_frequent_count / len(graduates_person_level)) * 100\n",
    "        })\n",
    "    \n",
    "    cat_df = pd.DataFrame(cat_summary)\n",
    "    print(cat_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean/Binary variables summary\n",
    "print(\"=== BOOLEAN/BINARY VARIABLES SUMMARY ===\")\n",
    "bool_cols = []\n",
    "binary_cols = []\n",
    "\n",
    "# Identify boolean and binary columns\n",
    "for col in graduates_person_level.columns:\n",
    "    unique_vals = graduates_person_level[col].dropna().unique()\n",
    "    if graduates_person_level[col].dtype == 'bool':\n",
    "        bool_cols.append(col)\n",
    "    elif len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, True, False, 'True', 'False', 'yes', 'no', 'Yes', 'No'}):\n",
    "        binary_cols.append(col)\n",
    "\n",
    "print(f\"Boolean variables: {len(bool_cols)}\")\n",
    "print(f\"Binary variables: {len(binary_cols)}\")\n",
    "\n",
    "all_binary = bool_cols + binary_cols\n",
    "if len(all_binary) > 0:\n",
    "    print(f\"\\nSummary of {len(all_binary)} boolean/binary variables:\")\n",
    "    binary_summary = []\n",
    "    for col in all_binary:\n",
    "        value_counts = graduates_person_level[col].value_counts()\n",
    "        if len(value_counts) >= 2:\n",
    "            binary_summary.append({\n",
    "                'Variable': col,\n",
    "                'True/1_Count': value_counts.iloc[0] if value_counts.index[0] in [1, True, 'True', 'yes', 'Yes'] else value_counts.iloc[1],\n",
    "                'False/0_Count': value_counts.iloc[1] if value_counts.index[0] in [1, True, 'True', 'yes', 'Yes'] else value_counts.iloc[0],\n",
    "                'True_Percentage': (value_counts.iloc[0] / len(graduates_person_level)) * 100 if value_counts.index[0] in [1, True, 'True', 'yes', 'Yes'] else (value_counts.iloc[1] / len(graduates_person_level)) * 100\n",
    "            })\n",
    "    \n",
    "    if binary_summary:\n",
    "        binary_df = pd.DataFrame(binary_summary)\n",
    "        print(binary_df.round(2).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a341b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key entrepreneurship and education variables summary\n",
    "print(\"=== KEY VARIABLES ANALYSIS ===\")\n",
    "\n",
    "# Education variables\n",
    "education_vars = [col for col in graduates_person_level.columns if 'education' in col.lower() or 'degree' in col.lower() or 'school' in col.lower()]\n",
    "print(f\"Education-related variables: {len(education_vars)}\")\n",
    "if education_vars:\n",
    "    print(\"Education variables:\", education_vars[:10], \"...\" if len(education_vars) > 10 else \"\")\n",
    "\n",
    "# Entrepreneurship variables\n",
    "entrepreneur_vars = [col for col in graduates_person_level.columns if any(keyword in col.lower() for keyword in ['found', 'entrepreneur', 'startup', 'cofounder', 'owner'])]\n",
    "print(f\"\\nEntrepreneurship-related variables: {len(entrepreneur_vars)}\")\n",
    "if entrepreneur_vars:\n",
    "    print(\"Entrepreneurship variables:\", entrepreneur_vars[:10], \"...\" if len(entrepreneur_vars) > 10 else \"\")\n",
    "\n",
    "# Time-windowed variables\n",
    "time_vars = [col for col in graduates_person_level.columns if any(time in col for time in ['_3_years', '_5_years', '_10_years'])]\n",
    "print(f\"\\nTime-windowed variables: {len(time_vars)}\")\n",
    "if time_vars:\n",
    "    print(\"Time-windowed variables:\", time_vars[:10], \"...\" if len(time_vars) > 10 else \"\")\n",
    "\n",
    "# Major category variables\n",
    "major_vars = [col for col in graduates_person_level.columns if 'major_' in col.lower()]\n",
    "print(f\"\\nMajor category variables: {len(major_vars)}\")\n",
    "if major_vars:\n",
    "    print(\"Major variables:\", major_vars[:10], \"...\" if len(major_vars) > 10 else \"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data preview for key variables\n",
    "print(\"=== SAMPLE DATA PREVIEW ===\")\n",
    "\n",
    "# Show a sample of key variables\n",
    "key_vars = ['person_id', 'university_name', 'graduation_year'] + \\\n",
    "           [col for col in graduates_person_level.columns if 'major_' in col][:5] + \\\n",
    "           [col for col in graduates_person_level.columns if 'found' in col.lower()][:5]\n",
    "\n",
    "# Filter to existing columns\n",
    "key_vars = [col for col in key_vars if col in graduates_person_level.columns]\n",
    "\n",
    "if key_vars:\n",
    "    print(f\"Sample of {len(key_vars)} key variables for first 10 observations:\")\n",
    "    print(graduates_person_level[key_vars].head(10).to_string(max_cols=None))\n",
    "else:\n",
    "    print(\"Key variables not found, showing first 5 columns:\")\n",
    "    print(graduates_person_level.iloc[:10, :5].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_count = graduates_person_level.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicate_count:,} ({(duplicate_count/len(graduates_person_level)*100):.2f}%)\")\n",
    "\n",
    "# Check for completely empty rows\n",
    "empty_rows = graduates_person_level.isnull().all(axis=1).sum()\n",
    "print(f\"Completely empty rows: {empty_rows:,}\")\n",
    "\n",
    "# Check for rows with mostly missing data (>80% missing)\n",
    "missing_threshold = 0.8\n",
    "mostly_missing = (graduates_person_level.isnull().sum(axis=1) / graduates_person_level.shape[1]) > missing_threshold\n",
    "print(f\"Rows with >{missing_threshold*100}% missing data: {mostly_missing.sum():,}\")\n",
    "\n",
    "# Check data consistency for key ID variables\n",
    "if 'person_id' in graduates_person_level.columns:\n",
    "    unique_ids = graduates_person_level['person_id'].nunique()\n",
    "    total_rows = len(graduates_person_level)\n",
    "    print(f\"Unique person IDs: {unique_ids:,} (vs {total_rows:,} total rows)\")\n",
    "    if unique_ids != total_rows:\n",
    "        print(f\"   Multiple records per person: {total_rows - unique_ids:,} duplicate person records\")\n",
    "\n",
    "print(f\"\\nOverall data completeness: {((graduates_person_level.notna().sum().sum()) / (graduates_person_level.shape[0] * graduates_person_level.shape[1]) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39603893",
   "metadata": {},
   "source": [
    "## Testing internally of the graduate file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d019c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the graduates_person_level data if not already loaded\n",
    "#graduates_person_level = pd.read_pickle('graduates_person_level_AnalysisFile.pkl')\n",
    "\n",
    "# Prepare the data for regression\n",
    "# Create dummy variables for college-year fixed effects\n",
    "graduates_person_level['college_year'] = graduates_person_level['unitid'].astype(str) + '_' + graduates_person_level['year_end_college'].astype(str)\n",
    "\n",
    "# Get dummies for college-year fixed effects\n",
    "college_year_dummies = pd.get_dummies(graduates_person_level['college_year'], prefix='college_year')\n",
    "\n",
    "# Prepare X variables (graduation year + college-year fixed effects)\n",
    "X = pd.concat([\n",
    "    graduates_person_level[['year_end_college']],\n",
    "    college_year_dummies\n",
    "], axis=1)\n",
    "\n",
    "# Use founded_within_10_years as dependent variable\n",
    "y = graduates_person_level['founded_within_10_years']\n",
    "\n",
    "# Create interaction terms for major categories with graduation year\n",
    "major_dummy_vars = [col for col in graduates_person_level.columns if col.startswith('major_')]\n",
    "\n",
    "# Create interaction terms (graduation year * major dummy)\n",
    "for major_var in major_dummy_vars:\n",
    "    graduates_person_level[f'{major_var}_x_year'] = graduates_person_level[major_var] * graduates_person_level['year_end_college']\n",
    "\n",
    "# Add interaction terms to X variables\n",
    "interaction_cols = [col for col in graduates_person_level.columns if col.endswith('_x_year')]\n",
    "X = pd.concat([\n",
    "    graduates_person_level[['year_end_college']],\n",
    "    graduates_person_level[major_dummy_vars],\n",
    "    graduates_person_level[interaction_cols],\n",
    "    college_year_dummies\n",
    "], axis=1)\n",
    "\n",
    "# Remove rows with missing values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X_clean = X[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "print(f\"Running regression with {len(X_clean):,} observations\")\n",
    "print(f\"Number of features: {X_clean.shape[1]}\")\n",
    "\n",
    "# Fit the regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_clean, y_clean)\n",
    "\n",
    "# Get coefficient for year_end_college\n",
    "year_coef = reg.coef_[0]\n",
    "print(f\"Coefficient for year_end_college: {year_coef:.6f}\")\n",
    "\n",
    "# Plot the coefficient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Year of Graduation'], [year_coef], color='steelblue', alpha=0.7)\n",
    "plt.title('Effect of Graduation Year on Founding a Company Within 10 Years')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xlabel('Variable')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value label on bar\n",
    "plt.text(0, year_coef + (abs(year_coef) * 0.1), f'{year_coef:.6f}', \n",
    "         ha='center', va='bottom' if year_coef > 0 else 'top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print regression summary\n",
    "print(f\"\\nRegression Results:\")\n",
    "print(f\"R-squared: {reg.score(X_clean, y_clean):.6f}\")\n",
    "print(f\"Number of observations: {len(X_clean):,}\")\n",
    "print(f\"Mean of dependent variable: {y_clean.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "graduates_person_level.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3725021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from linearmodels.iv import AbsorbingLS\n",
    "\n",
    "graduates_person_level['college_year'] = graduates_person_level['unitid'].astype(str) + '_' + graduates_person_level['year_end_college'].astype(str)\n",
    "\n",
    "# Make FEs categorical to save memory\n",
    "df = graduates_person_level.assign(\n",
    "    fe1=lambda d: d.unitid.astype('category'),    \n",
    "    fe_x=lambda d: d.year_end_college.astype('int16')    \n",
    ").dropna(subset=['founded_within_10_years','year_end_college','fe1','fe_x'])\n",
    "\n",
    "# Prepare dependent and independent variables\n",
    "dependent = df['founded_within_10_years']\n",
    "exog = pd.get_dummies(graduates_person_level['year_end_college'], prefix='xx')\n",
    "absorb = df[['unitid']]   # Fixed effects variable\n",
    "\n",
    "\n",
    "\n",
    "# Create and fit the model\n",
    "mod = AbsorbingLS(dependent, exog, absorb=absorb)\n",
    "res = mod.fit(\n",
    "    cov_type='clustered',\n",
    "    clusters=df[['fe1']]     # one- or multi-way clustering\n",
    ")\n",
    "print(res.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "universities_adopted_facebook.fb_date.value_counts()\n",
    "#graduates_person_level.columns\n",
    "#universities_adopted_facebook.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the company data CSV file efficiently\n",
    "print(\"Reading coresignal_company.csv file...\")\n",
    "print(\"Note: This is a large file (11GB), loading may take several minutes...\")\n",
    "\n",
    "coresignal_company = pd.read_csv('coresignal_company.csv')\n",
    "print(f\"Company data loaded: {len(coresignal_company):,} rows, {len(coresignal_company.columns)} columns\")\n",
    "print(\"Columns in company data:\", coresignal_company.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# First, let's examine the data we're working with\n",
    "print(\"Founder events shape:\", founder_events.shape)\n",
    "print(\"Company data shape:\", coresignal_company.shape)\n",
    "\n",
    "# Check the company_url column in founder_events\n",
    "print(\"\\nCompany URL info in founder_events:\")\n",
    "print(f\"Total founder events: {len(founder_events):,}\")\n",
    "print(f\"Non-null company URLs: {founder_events['company_url'].notna().sum():,}\")\n",
    "print(f\"Missing company URLs: {founder_events['company_url'].isna().sum():,}\")\n",
    "\n",
    "# Check if there's a URL column in coresignal_company\n",
    "print(\"\\nColumns in coresignal_company that might contain URLs:\")\n",
    "url_columns = [col for col in coresignal_company.columns if 'url' in col.lower() or 'link' in col.lower()]\n",
    "print(url_columns)\n",
    "\n",
    "# Also check for company name columns\n",
    "name_columns = [col for col in coresignal_company.columns if 'name' in col.lower() or 'company' in col.lower()]\n",
    "print(\"\\nColumns in coresignal_company that might contain company names:\")\n",
    "print(name_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a20f125c",
   "metadata": {},
   "source": [
    "# to dos and different changes after 10/06\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe378ec",
   "metadata": {},
   "source": [
    "GET THE DATA TO RUNJING \n",
    "\n",
    "- Create a better definition of co-founder if we can (being part of two companies by URL)\n",
    "    - Then add co-founding across different colleges. \n",
    "    - \n",
    "- Move the  franchisees into their own definition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528d854",
   "metadata": {},
   "source": [
    "# Data Dictionary for graduates_person_level Dataset\n",
    "\n",
    "This data dictionary describes all variables in the `graduates_person_level` dataset, which contains one row per graduate with their educational background and entrepreneurial outcomes.\n",
    "\n",
    "## Core Identification Variables\n",
    "- **linkedin_member_id**: Unique LinkedIn member identifier (renamed from member_id)\n",
    "- **unitid**: University identification code from IPEDS database\n",
    "\n",
    "## Educational Background Variables\n",
    "- **university_title**: Official name of the university (renamed from title_education)\n",
    "- **university_major_raw**: Raw major/degree description as reported (renamed from subtitle)\n",
    "- **university_major_clean**: Cleaned version of major description with degree prefixes removed\n",
    "- **university_major_categorized**: Major classified into standardized categories\n",
    "- **year_start_college**: Year the individual started college (renamed from year_from)\n",
    "- **year_end_college**: Year the individual graduated from college (renamed from year_to)\n",
    "\n",
    "## Major Category Dummy Variables (1 if major falls in category, 0 otherwise)\n",
    "- **major_engineering_or_computer**: Engineering, computer science, software, IT, robotics, AI, cybersecurity, architecture\n",
    "- **major_natural_science**: Biology, chemistry, physics, environmental science, geology, astronomy, biotechnology, neuroscience\n",
    "- **major_math**: Mathematics, statistics, data science, analytics\n",
    "- **major_education**: Education, teaching, instructional design, curriculum, pedagogy\n",
    "- **major_clinical_work**: Social work, pre-med, pharmacy, nursing, health, therapy, clinical work, counseling\n",
    "- **major_law_climinology**: Law, legal studies, criminology, criminal justice\n",
    "- **major_economics_and_finance**: Economics, finance, banking, investment, econometrics\n",
    "- **major_business_not_economics_finance**: Business, management, accounting, marketing, PR, administration, advertising, HR\n",
    "- **major_social_science_not_economics**: History, sociology, anthropology, political science, international relations, cultural studies\n",
    "- **major_arts**: Fine arts, design, music, theater, film, photography, fashion, visual arts, dance\n",
    "- **major_communications**: Communications, media, journalism, broadcasting\n",
    "- **major_english**: English, literature, writing\n",
    "- **major_psychology**: Psychology\n",
    "- **major_other**: All other majors not categorized above\n",
    "\n",
    "## Entrepreneurship Outcome Variables (Within X Years of Graduation)\n",
    "\n",
    "### 3-Year Variables\n",
    "- **is_founder_only_3_years**: Founded a company within 3 years (title contains \"founder\")\n",
    "- **is_owner_only_3_years**: Owned a company within 3 years (title contains \"owner\")\n",
    "- **is_founder_or_owner_3_years**: Either founded or owned a company within 3 years\n",
    "- **is_cofounder_or_coowner_title_3_years**: Co-founded or co-owned a company within 3 years (title-based)\n",
    "- **is_cofounder_only_title_3_years**: Co-founded a company within 3 years (title contains \"co-founder\")\n",
    "- **is_coowner_only_title_3_years**: Co-owned a company within 3 years (title contains \"co-owner\")\n",
    "- **is_founder_or_owner_with_url_3_years**: Founded/owned company with LinkedIn URL within 3 years\n",
    "- **is_founder_or_owner_inc_3_years**: Founded/owned incorporated company within 3 years\n",
    "- **cofound_coown_same_url_3_years**: Co-founded/co-owned company (same URL definition) within 3 years\n",
    "- **cofound_coown_same_url_num_schools_3_years**: Number of different universities among co-founders within 3 years\n",
    "- **cofound_coown_same_url_same_school_3_years**: Co-founded with someone from same university within 3 years\n",
    "- **cofound_coown_same_url_diff_school_3_years**: Co-founded with someone from different university within 3 years\n",
    "\n",
    "### 5-Year Variables\n",
    "- **is_founder_only_5_years**: Founded a company within 5 years\n",
    "- **is_owner_only_5_years**: Owned a company within 5 years\n",
    "- **is_founder_or_owner_5_years**: Either founded or owned a company within 5 years\n",
    "- **is_cofounder_or_coowner_title_5_years**: Co-founded or co-owned a company within 5 years\n",
    "- **is_cofounder_only_title_5_years**: Co-founded a company within 5 years\n",
    "- **is_coowner_only_title_5_years**: Co-owned a company within 5 years\n",
    "- **is_founder_or_owner_with_url_5_years**: Founded/owned company with LinkedIn URL within 5 years\n",
    "- **is_founder_or_owner_inc_5_years**: Founded/owned incorporated company within 5 years\n",
    "- **cofound_coown_same_url_5_years**: Co-founded/co-owned company (same URL definition) within 5 years\n",
    "- **cofound_coown_same_url_num_schools_5_years**: Number of different universities among co-founders within 5 years\n",
    "- **cofound_coown_same_url_same_school_5_years**: Co-founded with someone from same university within 5 years\n",
    "- **cofound_coown_same_url_diff_school_5_years**: Co-founded with someone from different university within 5 years\n",
    "\n",
    "### 10-Year Variables\n",
    "- **is_founder_only_10_years**: Founded a company within 10 years\n",
    "- **is_owner_only_10_years**: Owned a company within 10 years\n",
    "- **is_founder_or_owner_10_years**: Either founded or owned a company within 10 years\n",
    "- **is_cofounder_or_coowner_title_10_years**: Co-founded or co-owned a company within 10 years\n",
    "- **is_cofounder_only_title_10_years**: Co-founded a company within 10 years\n",
    "- **is_coowner_only_title_10_years**: Co-owned a company within 10 years\n",
    "- **is_founder_or_owner_with_url_10_years**: Founded/owned company with LinkedIn URL within 10 years\n",
    "- **is_founder_or_owner_inc_10_years**: Founded/owned incorporated company within 10 years\n",
    "- **cofound_coown_same_url_10_years**: Co-founded/co-owned company (same URL definition) within 10 years\n",
    "- **cofound_coown_same_url_num_schools_10_years**: Number of different universities among co-founders within 10 years\n",
    "- **cofound_coown_same_url_same_school_10_years**: Co-founded with someone from same university within 10 years\n",
    "- **cofound_coown_same_url_diff_school_10_years**: Co-founded with someone from different university within 10 years\n",
    "\n",
    "## Career Experience Variables (Within X Years of Graduation)\n",
    "- **worked_as_engineer_3_years**: Worked in engineering role within 3 years\n",
    "- **worked_as_engineer_5_years**: Worked in engineering role within 5 years\n",
    "- **worked_as_engineer_10_years**: Worked in engineering role within 10 years\n",
    "- **worked_in_sales_3_years**: Worked in sales role within 3 years\n",
    "- **worked_in_sales_5_years**: Worked in sales role within 5 years\n",
    "- **worked_in_sales_10_years**: Worked in sales role within 10 years\n",
    "\n",
    "## Data Notes\n",
    "1. **Sample**: Individuals who graduated with bachelor's degrees between 1995-2012\n",
    "2. **Entrepreneurship Definition**: Based on job titles containing \"founder\" or \"owner\" keywords\n",
    "3. **Data Cleaning**: Excluded non-ownership roles like \"product owner\", \"program owner\", titles with 4+ words\n",
    "4. **Co-founding**: Defined as multiple founders/owners at same company (by LinkedIn URL)\n",
    "5. **Time Windows**: All outcome variables measured within 3, 5, or 10 years post-graduation\n",
    "6. **Incorporated Companies**: Companies with names containing \"inc\", \"corp\", \"corporation\", \"co\", \"incorporated\"\n",
    "7. **Major Categories**: Based on keyword matching in degree descriptions\n",
    "\n",
    "## Data Structure\n",
    "- **Unit of Analysis**: One row per graduate\n",
    "- **Time Frame**: Graduates from 1995-2012, outcomes tracked through ~2020s\n",
    "- **Sample Size**: Approximately 1.5+ million graduates\n",
    "- **Data Source**: LinkedIn profiles via Coresignal, matched to IPEDS university data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f905c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable labels dictionary for Stata export\n",
    "variable_labels = {\n",
    "    # Core Identification Variables\n",
    "    'linkedin_member_id': 'Unique LinkedIn member identifier',\n",
    "    'unitid': 'University identification code from IPEDS database',\n",
    "    \n",
    "    # Educational Background Variables\n",
    "    'university_title': 'Official name of the university',\n",
    "    'university_major_raw': 'Raw major/degree description as reported',\n",
    "    'university_major_clean': 'Cleaned major description with degree prefixes removed',\n",
    "    'university_major_categorized': 'Major classified into standardized categories',\n",
    "    'year_start_college': 'Year the individual started college',\n",
    "    'year_end_college': 'Year the individual graduated from college',\n",
    "    \n",
    "    # Major Category Dummy Variables\n",
    "    'major_engineering_or_computer': 'Engineering, computer science, software, IT, robotics, AI',\n",
    "    'major_natural_science': 'Biology, chemistry, physics, environmental science, geology',\n",
    "    'major_math': 'Mathematics, statistics, data science, analytics',\n",
    "    'major_education': 'Education, teaching, instructional design, curriculum',\n",
    "    'major_clinical_work': 'Social work, pre-med, pharmacy, nursing, health, therapy',\n",
    "    'major_law_climinology': 'Law, legal studies, criminology, criminal justice',\n",
    "    'major_economics_and_finance': 'Economics, finance, banking, investment, econometrics',\n",
    "    'major_business_not_economics_finance': 'Business, management, accounting, marketing, PR, admin',\n",
    "    'major_social_science_not_economics': 'History, sociology, anthropology, political science',\n",
    "    'major_arts': 'Fine arts, design, music, theater, film, photography',\n",
    "    'major_communications': 'Communications, media, journalism, broadcasting',\n",
    "    'major_english': 'English, literature, writing',\n",
    "    'major_psychology': 'Psychology',\n",
    "    'major_other': 'All other majors not categorized above',\n",
    "    \n",
    "    # 3-Year Entrepreneurship Variables\n",
    "    'is_founder_only_3_years': 'Founded company within 3 years (title contains founder)',\n",
    "    'is_owner_only_3_years': 'Owned company within 3 years (title contains owner)',\n",
    "    'is_founder_or_owner_3_years': 'Founded or owned company within 3 years',\n",
    "    'is_cofounder_or_coowner_title_3_years': 'Co-founded or co-owned company within 3 years',\n",
    "    'is_cofounder_only_title_3_years': 'Co-founded company within 3 years',\n",
    "    'is_coowner_only_title_3_years': 'Co-owned company within 3 years',\n",
    "    'is_founder_or_owner_with_url_3_years': 'Founded/owned company with LinkedIn URL within 3 years',\n",
    "    'is_founder_or_owner_inc_3_years': 'Founded/owned incorporated company within 3 years',\n",
    "    'cofound_coown_same_url_3_years': 'Co-founded/co-owned company (same URL) within 3 years',\n",
    "    'cofound_coown_same_url_num_schools_3_years': 'Number different universities among co-founders within 3 years',\n",
    "    'cofound_coown_same_url_same_school_3_years': 'Co-founded with same university graduate within 3 years',\n",
    "    'cofound_coown_same_url_diff_school_3_years': 'Co-founded with different university graduate within 3 years',\n",
    "    \n",
    "    # 5-Year Entrepreneurship Variables\n",
    "    'is_founder_only_5_years': 'Founded company within 5 years (title contains founder)',\n",
    "    'is_owner_only_5_years': 'Owned company within 5 years (title contains owner)',\n",
    "    'is_founder_or_owner_5_years': 'Founded or owned company within 5 years',\n",
    "    'is_cofounder_or_coowner_title_5_years': 'Co-founded or co-owned company within 5 years',\n",
    "    'is_cofounder_only_title_5_years': 'Co-founded company within 5 years',\n",
    "    'is_coowner_only_title_5_years': 'Co-owned company within 5 years',\n",
    "    'is_founder_or_owner_with_url_5_years': 'Founded/owned company with LinkedIn URL within 5 years',\n",
    "    'is_founder_or_owner_inc_5_years': 'Founded/owned incorporated company within 5 years',\n",
    "    'cofound_coown_same_url_5_years': 'Co-founded/co-owned company (same URL) within 5 years',\n",
    "    'cofound_coown_same_url_num_schools_5_years': 'Number different universities among co-founders within 5 years',\n",
    "    'cofound_coown_same_url_same_school_5_years': 'Co-founded with same university graduate within 5 years',\n",
    "    'cofound_coown_same_url_diff_school_5_years': 'Co-founded with different university graduate within 5 years',\n",
    "    \n",
    "    # 10-Year Entrepreneurship Variables\n",
    "    'is_founder_only_10_years': 'Founded company within 10 years (title contains founder)',\n",
    "    'is_owner_only_10_years': 'Owned company within 10 years (title contains owner)',\n",
    "    'is_founder_or_owner_10_years': 'Founded or owned company within 10 years',\n",
    "    'is_cofounder_or_coowner_title_10_years': 'Co-founded or co-owned company within 10 years',\n",
    "    'is_cofounder_only_title_10_years': 'Co-founded company within 10 years',\n",
    "    'is_coowner_only_title_10_years': 'Co-owned company within 10 years',\n",
    "    'is_founder_or_owner_with_url_10_years': 'Founded/owned company with LinkedIn URL within 10 years',\n",
    "    'is_founder_or_owner_inc_10_years': 'Founded/owned incorporated company within 10 years',\n",
    "    'cofound_coown_same_url_10_years': 'Co-founded/co-owned company (same URL) within 10 years',\n",
    "    'cofound_coown_same_url_num_schools_10_years': 'Number different universities among co-founders within 10 years',\n",
    "    'cofound_coown_same_url_same_school_10_years': 'Co-founded with same university graduate within 10 years',\n",
    "    'cofound_coown_same_url_diff_school_10_years': 'Co-founded with different university graduate within 10 years',\n",
    "    \n",
    "    # Career Experience Variables\n",
    "    'worked_as_engineer_3_years': 'Worked in engineering role within 3 years',\n",
    "    'worked_as_engineer_5_years': 'Worked in engineering role within 5 years',\n",
    "    'worked_as_engineer_10_years': 'Worked in engineering role within 10 years',\n",
    "    'worked_in_sales_3_years': 'Worked in sales role within 3 years',\n",
    "    'worked_in_sales_5_years': 'Worked in sales role within 5 years',\n",
    "    'worked_in_sales_10_years': 'Worked in sales role within 10 years'\n",
    "}\n",
    "\n",
    "print(f\"Created variable labels for {len(variable_labels)} variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which variables exist in graduates_person_level and apply labels\n",
    "if 'graduates_person_level' in locals():\n",
    "    # Check which labeled variables exist in the dataset\n",
    "    existing_vars = set(graduates_person_level.columns)\n",
    "    labeled_vars = set(variable_labels.keys())\n",
    "    \n",
    "    # Variables that exist and have labels\n",
    "    vars_with_labels = existing_vars & labeled_vars\n",
    "    # Variables that exist but don't have labels\n",
    "    vars_without_labels = existing_vars - labeled_vars\n",
    "    # Variables that have labels but don't exist\n",
    "    labels_without_vars = labeled_vars - existing_vars\n",
    "    \n",
    "    print(\"Variable Label Matching Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total variables in dataset: {len(existing_vars)}\")\n",
    "    print(f\"Variables with labels: {len(vars_with_labels)}\")\n",
    "    print(f\"Variables without labels: {len(vars_without_labels)}\")\n",
    "    print(f\"Labels without matching variables: {len(labels_without_vars)}\")\n",
    "    \n",
    "    if len(vars_without_labels) > 0 and len(vars_without_labels) <= 10:\n",
    "        print(f\"\\nVariables without labels:\")\n",
    "        for var in sorted(vars_without_labels):\n",
    "            print(f\"  {var}\")\n",
    "    elif len(vars_without_labels) > 10:\n",
    "        print(f\"\\nFirst 10 variables without labels:\")\n",
    "        for var in sorted(list(vars_without_labels)[:10]):\n",
    "            print(f\"  {var}\")\n",
    "        print(f\"  ... and {len(vars_without_labels)-10} more\")\n",
    "    \n",
    "    # Create final labels dictionary with only existing variables\n",
    "    final_labels = {var: variable_labels[var] for var in vars_with_labels}\n",
    "    \n",
    "    # Add labels as metadata to the DataFrame\n",
    "    graduates_person_level.attrs['variable_labels'] = final_labels\n",
    "    \n",
    "    print(f\"\\nApplied {len(final_labels)} variable labels to graduates_person_level DataFrame\")\n",
    "    \n",
    "    # Export to Stata with variable labels\n",
    "    print(\"\\nExporting to Stata with variable labels...\")\n",
    "    graduates_person_level.to_stata(\n",
    "        \"graduates_person_level_with_labels_10082025.dta\",\n",
    "        variable_labels=final_labels,\n",
    "        version=118,\n",
    "        write_index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully exported {len(graduates_person_level):,} observations to Stata file\")\n",
    "    print(f\"File: graduates_person_level_with_labels_10072025.dta\")\n",
    "    print(\"Variable labels will be visible in Stata using 'describe' or 'codebook' commands\")\n",
    "    \n",
    "else:\n",
    "    print(\"graduates_person_level DataFrame not found in memory\")\n",
    "    print(\"You may need to run the earlier cells to create the dataset first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all binary variables to int type for cleaner summary statistics\n",
    "if 'graduates_person_level' in locals():\n",
    "    # Identify binary variables (variables with only 0, 1, and NaN values)\n",
    "    binary_vars = []\n",
    "    \n",
    "    for col in graduates_person_level.columns:\n",
    "        if graduates_person_level[col].dtype in ['bool', 'float64', 'int64']:\n",
    "            unique_vals = set(graduates_person_level[col].dropna().unique())\n",
    "            # Check if values are only 0 and 1 (or subset thereof)\n",
    "            if unique_vals.issubset({0, 1, 0.0, 1.0, True, False}):\n",
    "                binary_vars.append(col)\n",
    "    \n",
    "    print(f\"Converting {len(binary_vars)} binary variables to int type:\")\n",
    "    print(\"Binary variables found:\")\n",
    "    for var in binary_vars[:10]:  # Show first 10\n",
    "        print(f\"  {var}\")\n",
    "    if len(binary_vars) > 10:\n",
    "        print(f\"  ... and {len(binary_vars) - 10} more\")\n",
    "    \n",
    "    # Convert binary variables to int, handling NaN values\n",
    "    graduates_person_level_clean = graduates_person_level.copy()\n",
    "    for col in binary_vars:\n",
    "        # Convert to int, keeping NaN as NaN\n",
    "        graduates_person_level_clean[col] = graduates_person_level_clean[col].astype('Int64')\n",
    "    \n",
    "    print(f\"\\nConversion complete. Data types updated for {len(binary_vars)} variables.\")\n",
    "    \n",
    "else:\n",
    "    print(\"graduates_person_level DataFrame not found in memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary statistics with integer binary variables\n",
    "if 'graduates_person_level_clean' in locals():\n",
    "    \n",
    "    print(\"COMPREHENSIVE SUMMARY STATISTICS - GRADUATES_PERSON_LEVEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Basic dataset info\n",
    "    print(f\"Dataset Shape: {graduates_person_level_clean.shape[0]:,} rows  {graduates_person_level_clean.shape[1]} columns\")\n",
    "    print(f\"Memory Usage: {graduates_person_level_clean.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    print()\n",
    "    \n",
    "    # 1. CORE IDENTIFICATION VARIABLES\n",
    "    print(\"1. CORE IDENTIFICATION VARIABLES\")\n",
    "    print(\"-\" * 40)\n",
    "    id_vars = ['linkedin_member_id', 'unitid']\n",
    "    for var in id_vars:\n",
    "        if var in graduates_person_level_clean.columns:\n",
    "            series = graduates_person_level_clean[var]\n",
    "            print(f\"{var}:\")\n",
    "            print(f\"  Non-null: {series.notna().sum():,} ({series.notna().mean()*100:.1f}%)\")\n",
    "            print(f\"  Unique values: {series.nunique():,}\")\n",
    "    print()\n",
    "    \n",
    "    # 2. EDUCATIONAL BACKGROUND VARIABLES\n",
    "    print(\"2. EDUCATIONAL BACKGROUND VARIABLES\")\n",
    "    print(\"-\" * 40)\n",
    "    edu_vars = ['year_start_college', 'year_end_college', 'university_major_categorized']\n",
    "    for var in edu_vars:\n",
    "        if var in graduates_person_level_clean.columns:\n",
    "            series = graduates_person_level_clean[var]\n",
    "            if series.dtype in ['int64', 'Int64', 'float64']:\n",
    "                print(f\"{var}: Mean={series.mean():.1f}, Min={series.min()}, Max={series.max()}, Missing={series.isna().sum():,}\")\n",
    "            else:\n",
    "                print(f\"{var}: {series.nunique():,} unique values, Missing={series.isna().sum():,}\")\n",
    "    print()\n",
    "    \n",
    "    # 3. MAJOR CATEGORIES (showing as percentages)\n",
    "    print(\"3. MAJOR CATEGORY DISTRIBUTION\")\n",
    "    print(\"-\" * 40)\n",
    "    major_vars = [col for col in graduates_person_level_clean.columns if col.startswith('major_')]\n",
    "    total_grads = len(graduates_person_level_clean)\n",
    "    \n",
    "    for var in sorted(major_vars):\n",
    "        count = graduates_person_level_clean[var].sum()\n",
    "        pct = (count / total_grads) * 100\n",
    "        print(f\"{var:<35}: {count:>8,} ({pct:>5.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # 4. ENTREPRENEURSHIP OUTCOMES (3, 5, 10 years)\n",
    "    print(\"4. ENTREPRENEURSHIP OUTCOMES BY TIME HORIZON\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for years in [3, 5, 10]:\n",
    "        print(f\"\\n{years}-Year Outcomes:\")\n",
    "        outcome_vars = [col for col in graduates_person_level_clean.columns if col.endswith(f'_{years}_years')]\n",
    "        \n",
    "        for var in sorted(outcome_vars)[:8]:  # Show first 8 to avoid clutter\n",
    "            if graduates_person_level_clean[var].dtype in ['int64', 'Int64', 'bool']:\n",
    "                count = graduates_person_level_clean[var].sum()\n",
    "                pct = (count / total_grads) * 100\n",
    "                print(f\"  {var:<40}: {count:>6,} ({pct:>4.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5. DESCRIPTIVE STATISTICS FOR KEY VARIABLES\n",
    "    print(\"5. DESCRIPTIVE STATISTICS FOR CONTINUOUS VARIABLES\")\n",
    "    print(\"-\" * 40)\n",
    "    continuous_vars = ['year_start_college', 'year_end_college']\n",
    "    continuous_vars += [col for col in graduates_person_level_clean.columns if 'num_schools' in col]\n",
    "    \n",
    "    desc_stats = graduates_person_level_clean[continuous_vars].describe()\n",
    "    print(desc_stats.round(2))\n",
    "    print()\n",
    "    \n",
    "    # 6. MISSING DATA SUMMARY\n",
    "    print(\"6. MISSING DATA SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "    missing_summary = graduates_person_level_clean.isnull().sum()\n",
    "    missing_pct = (missing_summary / len(graduates_person_level_clean)) * 100\n",
    "    \n",
    "    vars_with_missing = missing_summary[missing_summary > 0].sort_values(ascending=False)\n",
    "    if len(vars_with_missing) > 0:\n",
    "        print(\"Variables with missing data:\")\n",
    "        for var, count in vars_with_missing.head(10).items():\n",
    "            pct = missing_pct[var]\n",
    "            print(f\"  {var:<40}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "        if len(vars_with_missing) > 10:\n",
    "            print(f\"  ... and {len(vars_with_missing) - 10} more variables with missing data\")\n",
    "    else:\n",
    "        print(\"No missing data found!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Summary statistics generation complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"graduates_person_level_clean not found. Run the previous cell first to convert data types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e0cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01661327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f98391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "J Guzman Private Kernel",
   "language": "python",
   "name": "jgpriv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
